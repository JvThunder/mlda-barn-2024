{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>success</th>\n",
       "      <th>actual_time</th>\n",
       "      <th>optimal_time</th>\n",
       "      <th>world_idx</th>\n",
       "      <th>timestep</th>\n",
       "      <th>goal_x</th>\n",
       "      <th>goal_y</th>\n",
       "      <th>lidar_0</th>\n",
       "      <th>lidar_1</th>\n",
       "      <th>lidar_2</th>\n",
       "      <th>...</th>\n",
       "      <th>lidar_359</th>\n",
       "      <th>pos_x</th>\n",
       "      <th>pos_y</th>\n",
       "      <th>pose_heading</th>\n",
       "      <th>twist_linear</th>\n",
       "      <th>twist_angular</th>\n",
       "      <th>cmd_vel_linear</th>\n",
       "      <th>cmd_vel_angular</th>\n",
       "      <th>local_goal_x</th>\n",
       "      <th>local_goal_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>12.28</td>\n",
       "      <td>6.817982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.551471</td>\n",
       "      <td>3.583072</td>\n",
       "      <td>3.590224</td>\n",
       "      <td>...</td>\n",
       "      <td>2.415017</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.007838</td>\n",
       "      <td>1.305499</td>\n",
       "      <td>0.058535</td>\n",
       "      <td>0.017162</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.048861</td>\n",
       "      <td>0.979970</td>\n",
       "      <td>0.268035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>12.28</td>\n",
       "      <td>6.817982</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.598488</td>\n",
       "      <td>3.588387</td>\n",
       "      <td>3.618532</td>\n",
       "      <td>...</td>\n",
       "      <td>2.424911</td>\n",
       "      <td>0.004223</td>\n",
       "      <td>0.015791</td>\n",
       "      <td>1.310372</td>\n",
       "      <td>0.089367</td>\n",
       "      <td>0.058952</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.065233</td>\n",
       "      <td>0.972612</td>\n",
       "      <td>0.262769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>12.28</td>\n",
       "      <td>6.817982</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.594980</td>\n",
       "      <td>3.613630</td>\n",
       "      <td>3.679848</td>\n",
       "      <td>...</td>\n",
       "      <td>2.442092</td>\n",
       "      <td>0.007091</td>\n",
       "      <td>0.026704</td>\n",
       "      <td>1.317660</td>\n",
       "      <td>0.120093</td>\n",
       "      <td>0.084446</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.081682</td>\n",
       "      <td>0.986936</td>\n",
       "      <td>0.261523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>12.28</td>\n",
       "      <td>6.817982</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.622268</td>\n",
       "      <td>3.693125</td>\n",
       "      <td>3.685916</td>\n",
       "      <td>...</td>\n",
       "      <td>2.471114</td>\n",
       "      <td>0.011333</td>\n",
       "      <td>0.040561</td>\n",
       "      <td>1.327250</td>\n",
       "      <td>0.151487</td>\n",
       "      <td>0.101972</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.096369</td>\n",
       "      <td>0.974630</td>\n",
       "      <td>0.251622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>12.28</td>\n",
       "      <td>6.817982</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.699742</td>\n",
       "      <td>3.704420</td>\n",
       "      <td>3.794361</td>\n",
       "      <td>...</td>\n",
       "      <td>2.534025</td>\n",
       "      <td>0.014685</td>\n",
       "      <td>0.057351</td>\n",
       "      <td>1.339300</td>\n",
       "      <td>0.180620</td>\n",
       "      <td>0.126776</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.107049</td>\n",
       "      <td>0.984210</td>\n",
       "      <td>0.245075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 376 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   success  actual_time  optimal_time  world_idx  timestep  goal_x  goal_y  \\\n",
       "0     True        12.28      6.817982          0         0     0.0    10.0   \n",
       "1     True        12.28      6.817982          0         1     0.0    10.0   \n",
       "2     True        12.28      6.817982          0         2     0.0    10.0   \n",
       "3     True        12.28      6.817982          0         3     0.0    10.0   \n",
       "4     True        12.28      6.817982          0         4     0.0    10.0   \n",
       "\n",
       "    lidar_0   lidar_1   lidar_2  ...  lidar_359     pos_x     pos_y  \\\n",
       "0  3.551471  3.583072  3.590224  ...   2.415017  0.002083  0.007838   \n",
       "1  3.598488  3.588387  3.618532  ...   2.424911  0.004223  0.015791   \n",
       "2  3.594980  3.613630  3.679848  ...   2.442092  0.007091  0.026704   \n",
       "3  3.622268  3.693125  3.685916  ...   2.471114  0.011333  0.040561   \n",
       "4  3.699742  3.704420  3.794361  ...   2.534025  0.014685  0.057351   \n",
       "\n",
       "   pose_heading  twist_linear  twist_angular  cmd_vel_linear  cmd_vel_angular  \\\n",
       "0      1.305499      0.058535       0.017162            0.09         0.048861   \n",
       "1      1.310372      0.089367       0.058952            0.12         0.065233   \n",
       "2      1.317660      0.120093       0.084446            0.15         0.081682   \n",
       "3      1.327250      0.151487       0.101972            0.18         0.096369   \n",
       "4      1.339300      0.180620       0.126776            0.21         0.107049   \n",
       "\n",
       "   local_goal_x  local_goal_y  \n",
       "0      0.979970      0.268035  \n",
       "1      0.972612      0.262769  \n",
       "2      0.986936      0.261523  \n",
       "3      0.974630      0.251622  \n",
       "4      0.984210      0.245075  \n",
       "\n",
       "[5 rows x 376 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('../../data_10Hz.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>success</th>\n",
       "      <th>actual_time</th>\n",
       "      <th>optimal_time</th>\n",
       "      <th>world_idx</th>\n",
       "      <th>timestep</th>\n",
       "      <th>goal_x</th>\n",
       "      <th>goal_y</th>\n",
       "      <th>lidar_0</th>\n",
       "      <th>lidar_1</th>\n",
       "      <th>lidar_2</th>\n",
       "      <th>...</th>\n",
       "      <th>lidar_359</th>\n",
       "      <th>pos_x</th>\n",
       "      <th>pos_y</th>\n",
       "      <th>pose_heading</th>\n",
       "      <th>twist_linear</th>\n",
       "      <th>twist_angular</th>\n",
       "      <th>cmd_vel_linear</th>\n",
       "      <th>cmd_vel_angular</th>\n",
       "      <th>local_goal_x</th>\n",
       "      <th>local_goal_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>12.280</td>\n",
       "      <td>6.817982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.551471</td>\n",
       "      <td>3.583072</td>\n",
       "      <td>3.590224</td>\n",
       "      <td>...</td>\n",
       "      <td>2.415017</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.007838</td>\n",
       "      <td>1.305499</td>\n",
       "      <td>0.058535</td>\n",
       "      <td>0.017162</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.048861</td>\n",
       "      <td>0.979970</td>\n",
       "      <td>0.268035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>12.280</td>\n",
       "      <td>6.817982</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.598488</td>\n",
       "      <td>3.588387</td>\n",
       "      <td>3.618532</td>\n",
       "      <td>...</td>\n",
       "      <td>2.424911</td>\n",
       "      <td>0.004223</td>\n",
       "      <td>0.015791</td>\n",
       "      <td>1.310372</td>\n",
       "      <td>0.089367</td>\n",
       "      <td>0.058952</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.065233</td>\n",
       "      <td>0.972612</td>\n",
       "      <td>0.262769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>12.280</td>\n",
       "      <td>6.817982</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.594980</td>\n",
       "      <td>3.613630</td>\n",
       "      <td>3.679848</td>\n",
       "      <td>...</td>\n",
       "      <td>2.442092</td>\n",
       "      <td>0.007091</td>\n",
       "      <td>0.026704</td>\n",
       "      <td>1.317660</td>\n",
       "      <td>0.120093</td>\n",
       "      <td>0.084446</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.081682</td>\n",
       "      <td>0.986936</td>\n",
       "      <td>0.261523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>12.280</td>\n",
       "      <td>6.817982</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.622268</td>\n",
       "      <td>3.693125</td>\n",
       "      <td>3.685916</td>\n",
       "      <td>...</td>\n",
       "      <td>2.471114</td>\n",
       "      <td>0.011333</td>\n",
       "      <td>0.040561</td>\n",
       "      <td>1.327250</td>\n",
       "      <td>0.151487</td>\n",
       "      <td>0.101972</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.096369</td>\n",
       "      <td>0.974630</td>\n",
       "      <td>0.251622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>12.280</td>\n",
       "      <td>6.817982</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.699742</td>\n",
       "      <td>3.704420</td>\n",
       "      <td>3.794361</td>\n",
       "      <td>...</td>\n",
       "      <td>2.534025</td>\n",
       "      <td>0.014685</td>\n",
       "      <td>0.057351</td>\n",
       "      <td>1.339300</td>\n",
       "      <td>0.180620</td>\n",
       "      <td>0.126776</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.107049</td>\n",
       "      <td>0.984210</td>\n",
       "      <td>0.245075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>True</td>\n",
       "      <td>12.331</td>\n",
       "      <td>6.739206</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.111870</td>\n",
       "      <td>0.285334</td>\n",
       "      <td>8.834061</td>\n",
       "      <td>1.752140</td>\n",
       "      <td>0.800408</td>\n",
       "      <td>0.006167</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.070281</td>\n",
       "      <td>1.014328</td>\n",
       "      <td>0.024174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>True</td>\n",
       "      <td>12.331</td>\n",
       "      <td>6.739206</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.140113</td>\n",
       "      <td>0.270799</td>\n",
       "      <td>8.912748</td>\n",
       "      <td>1.756147</td>\n",
       "      <td>0.799818</td>\n",
       "      <td>0.047104</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.078307</td>\n",
       "      <td>1.012735</td>\n",
       "      <td>0.028929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>True</td>\n",
       "      <td>12.331</td>\n",
       "      <td>6.739206</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.199078</td>\n",
       "      <td>0.256008</td>\n",
       "      <td>8.991303</td>\n",
       "      <td>1.760437</td>\n",
       "      <td>0.799527</td>\n",
       "      <td>0.104954</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.077049</td>\n",
       "      <td>1.017621</td>\n",
       "      <td>0.047089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>True</td>\n",
       "      <td>12.331</td>\n",
       "      <td>6.739206</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.268189</td>\n",
       "      <td>0.240563</td>\n",
       "      <td>9.069793</td>\n",
       "      <td>1.770813</td>\n",
       "      <td>0.800083</td>\n",
       "      <td>0.110512</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.089043</td>\n",
       "      <td>0.968264</td>\n",
       "      <td>0.047857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>True</td>\n",
       "      <td>12.331</td>\n",
       "      <td>6.739206</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.525588</td>\n",
       "      <td>0.224309</td>\n",
       "      <td>9.148159</td>\n",
       "      <td>1.778524</td>\n",
       "      <td>0.800480</td>\n",
       "      <td>0.023514</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.064996</td>\n",
       "      <td>0.888590</td>\n",
       "      <td>0.040826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>391 rows Ã— 376 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     success  actual_time  optimal_time  world_idx  timestep  goal_x  goal_y  \\\n",
       "0       True       12.280      6.817982          0         0     0.0    10.0   \n",
       "1       True       12.280      6.817982          0         1     0.0    10.0   \n",
       "2       True       12.280      6.817982          0         2     0.0    10.0   \n",
       "3       True       12.280      6.817982          0         3     0.0    10.0   \n",
       "4       True       12.280      6.817982          0         4     0.0    10.0   \n",
       "..       ...          ...           ...        ...       ...     ...     ...   \n",
       "386     True       12.331      6.739206          0       126     0.0    10.0   \n",
       "387     True       12.331      6.739206          0       127     0.0    10.0   \n",
       "388     True       12.331      6.739206          0       128     0.0    10.0   \n",
       "389     True       12.331      6.739206          0       129     0.0    10.0   \n",
       "390     True       12.331      6.739206          0       130     0.0    10.0   \n",
       "\n",
       "      lidar_0   lidar_1   lidar_2  ...  lidar_359     pos_x     pos_y  \\\n",
       "0    3.551471  3.583072  3.590224  ...   2.415017  0.002083  0.007838   \n",
       "1    3.598488  3.588387  3.618532  ...   2.424911  0.004223  0.015791   \n",
       "2    3.594980  3.613630  3.679848  ...   2.442092  0.007091  0.026704   \n",
       "3    3.622268  3.693125  3.685916  ...   2.471114  0.011333  0.040561   \n",
       "4    3.699742  3.704420  3.794361  ...   2.534025  0.014685  0.057351   \n",
       "..        ...       ...       ...  ...        ...       ...       ...   \n",
       "386  5.000000  5.000000  5.000000  ...   3.111870  0.285334  8.834061   \n",
       "387  5.000000  5.000000  5.000000  ...   3.140113  0.270799  8.912748   \n",
       "388  5.000000  5.000000  5.000000  ...   3.199078  0.256008  8.991303   \n",
       "389  5.000000  5.000000  5.000000  ...   3.268189  0.240563  9.069793   \n",
       "390  5.000000  5.000000  5.000000  ...   3.525588  0.224309  9.148159   \n",
       "\n",
       "     pose_heading  twist_linear  twist_angular  cmd_vel_linear  \\\n",
       "0        1.305499      0.058535       0.017162            0.09   \n",
       "1        1.310372      0.089367       0.058952            0.12   \n",
       "2        1.317660      0.120093       0.084446            0.15   \n",
       "3        1.327250      0.151487       0.101972            0.18   \n",
       "4        1.339300      0.180620       0.126776            0.21   \n",
       "..            ...           ...            ...             ...   \n",
       "386      1.752140      0.800408       0.006167            0.80   \n",
       "387      1.756147      0.799818       0.047104            0.80   \n",
       "388      1.760437      0.799527       0.104954            0.80   \n",
       "389      1.770813      0.800083       0.110512            0.80   \n",
       "390      1.778524      0.800480       0.023514            0.80   \n",
       "\n",
       "     cmd_vel_angular  local_goal_x  local_goal_y  \n",
       "0           0.048861      0.979970      0.268035  \n",
       "1           0.065233      0.972612      0.262769  \n",
       "2           0.081682      0.986936      0.261523  \n",
       "3           0.096369      0.974630      0.251622  \n",
       "4           0.107049      0.984210      0.245075  \n",
       "..               ...           ...           ...  \n",
       "386         0.070281      1.014328      0.024174  \n",
       "387         0.078307      1.012735      0.028929  \n",
       "388         0.077049      1.017621      0.047089  \n",
       "389         0.089043      0.968264      0.047857  \n",
       "390         0.064996      0.888590      0.040826  \n",
       "\n",
       "[391 rows x 376 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['world_idx'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove rows with success = 0\n",
    "df = df[df['success'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check number of local_goal_x ** 2 + local_goal_y ** 2 < 0.25\n",
    "# df['distance'] = df['local_goal_x'] ** 2 + df['local_goal_y'] ** 2\n",
    "# df = df[df['distance'] > 0.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([8.61000e+02, 9.70000e+01, 2.17000e+02, 2.45000e+02, 2.68000e+02,\n",
       "        3.21000e+02, 3.13000e+02, 5.56000e+02, 7.04000e+02, 8.66000e+02,\n",
       "        1.03900e+03, 1.43900e+03, 1.50300e+03, 5.48200e+03, 2.59600e+03,\n",
       "        3.03200e+03, 3.75800e+03, 4.83100e+03, 6.18200e+03, 8.56400e+03,\n",
       "        1.16310e+04, 1.67590e+04, 3.13700e+04, 7.52520e+04, 1.11437e+05,\n",
       "        1.17948e+05, 5.19880e+04, 2.36980e+04, 1.47700e+04, 1.04690e+04,\n",
       "        7.94800e+03, 6.64000e+03, 5.44700e+03, 4.25000e+03, 3.62100e+03,\n",
       "        2.89900e+03, 5.12100e+03, 2.00200e+03, 1.67500e+03, 1.34200e+03,\n",
       "        1.18900e+03, 9.40000e+02, 8.86000e+02, 4.68000e+02, 4.62000e+02,\n",
       "        3.36000e+02, 2.42000e+02, 2.07000e+02, 1.41000e+02, 9.61000e+02]),\n",
       " array([-1.57079633e+00, -1.50796447e+00, -1.44513262e+00, -1.38230077e+00,\n",
       "        -1.31946891e+00, -1.25663706e+00, -1.19380521e+00, -1.13097336e+00,\n",
       "        -1.06814150e+00, -1.00530965e+00, -9.42477796e-01, -8.79645943e-01,\n",
       "        -8.16814090e-01, -7.53982237e-01, -6.91150384e-01, -6.28318531e-01,\n",
       "        -5.65486678e-01, -5.02654825e-01, -4.39822972e-01, -3.76991118e-01,\n",
       "        -3.14159265e-01, -2.51327412e-01, -1.88495559e-01, -1.25663706e-01,\n",
       "        -6.28318531e-02,  2.22044605e-16,  6.28318531e-02,  1.25663706e-01,\n",
       "         1.88495559e-01,  2.51327412e-01,  3.14159265e-01,  3.76991118e-01,\n",
       "         4.39822972e-01,  5.02654825e-01,  5.65486678e-01,  6.28318531e-01,\n",
       "         6.91150384e-01,  7.53982237e-01,  8.16814090e-01,  8.79645943e-01,\n",
       "         9.42477796e-01,  1.00530965e+00,  1.06814150e+00,  1.13097336e+00,\n",
       "         1.19380521e+00,  1.25663706e+00,  1.31946891e+00,  1.38230077e+00,\n",
       "         1.44513262e+00,  1.50796447e+00,  1.57079633e+00]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot histogram of cmd_vel_angular\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(df['cmd_vel_angular'], bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot histogram of cmd_vel_angular\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.hist(df_filtered['cmd_vel_angular'], bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "success\n",
       "True    554973\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of unsuccesful worlds\n",
    "df['success'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_time</th>\n",
       "      <th>optimal_time</th>\n",
       "      <th>world_idx</th>\n",
       "      <th>timestep</th>\n",
       "      <th>goal_x</th>\n",
       "      <th>goal_y</th>\n",
       "      <th>lidar_0</th>\n",
       "      <th>lidar_1</th>\n",
       "      <th>lidar_2</th>\n",
       "      <th>lidar_3</th>\n",
       "      <th>...</th>\n",
       "      <th>lidar_359</th>\n",
       "      <th>pos_x</th>\n",
       "      <th>pos_y</th>\n",
       "      <th>pose_heading</th>\n",
       "      <th>twist_linear</th>\n",
       "      <th>twist_angular</th>\n",
       "      <th>cmd_vel_linear</th>\n",
       "      <th>cmd_vel_angular</th>\n",
       "      <th>local_goal_x</th>\n",
       "      <th>local_goal_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>554973.000000</td>\n",
       "      <td>554973.000000</td>\n",
       "      <td>554973.000000</td>\n",
       "      <td>554973.000000</td>\n",
       "      <td>554973.0</td>\n",
       "      <td>554973.0</td>\n",
       "      <td>554973.000000</td>\n",
       "      <td>554973.000000</td>\n",
       "      <td>554973.000000</td>\n",
       "      <td>554973.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>554973.000000</td>\n",
       "      <td>554973.000000</td>\n",
       "      <td>554973.000000</td>\n",
       "      <td>554973.000000</td>\n",
       "      <td>554973.000000</td>\n",
       "      <td>554973.000000</td>\n",
       "      <td>554973.000000</td>\n",
       "      <td>554973.000000</td>\n",
       "      <td>554973.000000</td>\n",
       "      <td>554973.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.259048</td>\n",
       "      <td>5.716841</td>\n",
       "      <td>151.319140</td>\n",
       "      <td>313.696198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.626697</td>\n",
       "      <td>2.610495</td>\n",
       "      <td>2.594688</td>\n",
       "      <td>2.580224</td>\n",
       "      <td>...</td>\n",
       "      <td>2.570933</td>\n",
       "      <td>-0.026526</td>\n",
       "      <td>4.470110</td>\n",
       "      <td>1.549228</td>\n",
       "      <td>0.775685</td>\n",
       "      <td>-0.000481</td>\n",
       "      <td>0.776109</td>\n",
       "      <td>-0.001090</td>\n",
       "      <td>0.977993</td>\n",
       "      <td>0.001147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.273365</td>\n",
       "      <td>0.373244</td>\n",
       "      <td>86.703978</td>\n",
       "      <td>192.859723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.296723</td>\n",
       "      <td>1.294866</td>\n",
       "      <td>1.293297</td>\n",
       "      <td>1.293029</td>\n",
       "      <td>...</td>\n",
       "      <td>1.310691</td>\n",
       "      <td>0.573949</td>\n",
       "      <td>2.647403</td>\n",
       "      <td>0.413160</td>\n",
       "      <td>0.124030</td>\n",
       "      <td>0.316548</td>\n",
       "      <td>0.119066</td>\n",
       "      <td>0.290502</td>\n",
       "      <td>0.152300</td>\n",
       "      <td>0.207453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.165000</td>\n",
       "      <td>5.012248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.292027</td>\n",
       "      <td>0.287642</td>\n",
       "      <td>0.285270</td>\n",
       "      <td>0.281570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217051</td>\n",
       "      <td>-1.811188</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>-3.141152</td>\n",
       "      <td>-0.318413</td>\n",
       "      <td>-2.506347</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-1.570796</td>\n",
       "      <td>-1.024131</td>\n",
       "      <td>-1.025240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.404000</td>\n",
       "      <td>5.449447</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.538159</td>\n",
       "      <td>1.527395</td>\n",
       "      <td>1.516633</td>\n",
       "      <td>1.505974</td>\n",
       "      <td>...</td>\n",
       "      <td>1.476724</td>\n",
       "      <td>-0.378162</td>\n",
       "      <td>2.188165</td>\n",
       "      <td>1.436482</td>\n",
       "      <td>0.800021</td>\n",
       "      <td>-0.083711</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>-0.089032</td>\n",
       "      <td>0.998515</td>\n",
       "      <td>-0.058111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11.612000</td>\n",
       "      <td>5.628741</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.648689</td>\n",
       "      <td>2.628465</td>\n",
       "      <td>2.607874</td>\n",
       "      <td>2.588119</td>\n",
       "      <td>...</td>\n",
       "      <td>2.566847</td>\n",
       "      <td>-0.030590</td>\n",
       "      <td>4.385300</td>\n",
       "      <td>1.585563</td>\n",
       "      <td>0.800496</td>\n",
       "      <td>-0.002824</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>-0.007541</td>\n",
       "      <td>1.006663</td>\n",
       "      <td>-0.003594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.027000</td>\n",
       "      <td>5.923911</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>462.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.427153</td>\n",
       "      <td>3.398267</td>\n",
       "      <td>3.370909</td>\n",
       "      <td>3.345454</td>\n",
       "      <td>...</td>\n",
       "      <td>3.367440</td>\n",
       "      <td>0.312517</td>\n",
       "      <td>6.744542</td>\n",
       "      <td>1.710501</td>\n",
       "      <td>0.801997</td>\n",
       "      <td>0.061823</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.069420</td>\n",
       "      <td>1.014649</td>\n",
       "      <td>0.050435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>33.139000</td>\n",
       "      <td>6.930695</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>1670.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.894076</td>\n",
       "      <td>9.340227</td>\n",
       "      <td>3.141573</td>\n",
       "      <td>0.821323</td>\n",
       "      <td>2.281988</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.570796</td>\n",
       "      <td>1.051611</td>\n",
       "      <td>1.023490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 375 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         actual_time   optimal_time      world_idx       timestep    goal_x  \\\n",
       "count  554973.000000  554973.000000  554973.000000  554973.000000  554973.0   \n",
       "mean       12.259048       5.716841     151.319140     313.696198       0.0   \n",
       "std         2.273365       0.373244      86.703978     192.859723       0.0   \n",
       "min        11.165000       5.012248       0.000000       0.000000       0.0   \n",
       "25%        11.404000       5.449447      77.000000     154.000000       0.0   \n",
       "50%        11.612000       5.628741     151.000000     308.000000       0.0   \n",
       "75%        12.027000       5.923911     227.000000     462.000000       0.0   \n",
       "max        33.139000       6.930695     299.000000    1670.000000       0.0   \n",
       "\n",
       "         goal_y        lidar_0        lidar_1        lidar_2        lidar_3  \\\n",
       "count  554973.0  554973.000000  554973.000000  554973.000000  554973.000000   \n",
       "mean       10.0       2.626697       2.610495       2.594688       2.580224   \n",
       "std         0.0       1.296723       1.294866       1.293297       1.293029   \n",
       "min        10.0       0.292027       0.287642       0.285270       0.281570   \n",
       "25%        10.0       1.538159       1.527395       1.516633       1.505974   \n",
       "50%        10.0       2.648689       2.628465       2.607874       2.588119   \n",
       "75%        10.0       3.427153       3.398267       3.370909       3.345454   \n",
       "max        10.0       5.000000       5.000000       5.000000       5.000000   \n",
       "\n",
       "       ...      lidar_359          pos_x          pos_y   pose_heading  \\\n",
       "count  ...  554973.000000  554973.000000  554973.000000  554973.000000   \n",
       "mean   ...       2.570933      -0.026526       4.470110       1.549228   \n",
       "std    ...       1.310691       0.573949       2.647403       0.413160   \n",
       "min    ...       0.217051      -1.811188       0.000263      -3.141152   \n",
       "25%    ...       1.476724      -0.378162       2.188165       1.436482   \n",
       "50%    ...       2.566847      -0.030590       4.385300       1.585563   \n",
       "75%    ...       3.367440       0.312517       6.744542       1.710501   \n",
       "max    ...       5.000000       1.894076       9.340227       3.141573   \n",
       "\n",
       "        twist_linear  twist_angular  cmd_vel_linear  cmd_vel_angular  \\\n",
       "count  554973.000000  554973.000000   554973.000000    554973.000000   \n",
       "mean        0.775685      -0.000481        0.776109        -0.001090   \n",
       "std         0.124030       0.316548        0.119066         0.290502   \n",
       "min        -0.318413      -2.506347       -0.300000        -1.570796   \n",
       "25%         0.800021      -0.083711        0.800000        -0.089032   \n",
       "50%         0.800496      -0.002824        0.800000        -0.007541   \n",
       "75%         0.801997       0.061823        0.800000         0.069420   \n",
       "max         0.821323       2.281988        0.800000         1.570796   \n",
       "\n",
       "        local_goal_x   local_goal_y  \n",
       "count  554973.000000  554973.000000  \n",
       "mean        0.977993       0.001147  \n",
       "std         0.152300       0.207453  \n",
       "min        -1.024131      -1.025240  \n",
       "25%         0.998515      -0.058111  \n",
       "50%         1.006663      -0.003594  \n",
       "75%         1.014649       0.050435  \n",
       "max         1.051611       1.023490  \n",
       "\n",
       "[8 rows x 375 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [success, actual_time, optimal_time, world_idx, timestep, goal_x, goal_y, lidar_0, lidar_1, lidar_2, lidar_3, lidar_4, lidar_5, lidar_6, lidar_7, lidar_8, lidar_9, lidar_10, lidar_11, lidar_12, lidar_13, lidar_14, lidar_15, lidar_16, lidar_17, lidar_18, lidar_19, lidar_20, lidar_21, lidar_22, lidar_23, lidar_24, lidar_25, lidar_26, lidar_27, lidar_28, lidar_29, lidar_30, lidar_31, lidar_32, lidar_33, lidar_34, lidar_35, lidar_36, lidar_37, lidar_38, lidar_39, lidar_40, lidar_41, lidar_42, lidar_43, lidar_44, lidar_45, lidar_46, lidar_47, lidar_48, lidar_49, lidar_50, lidar_51, lidar_52, lidar_53, lidar_54, lidar_55, lidar_56, lidar_57, lidar_58, lidar_59, lidar_60, lidar_61, lidar_62, lidar_63, lidar_64, lidar_65, lidar_66, lidar_67, lidar_68, lidar_69, lidar_70, lidar_71, lidar_72, lidar_73, lidar_74, lidar_75, lidar_76, lidar_77, lidar_78, lidar_79, lidar_80, lidar_81, lidar_82, lidar_83, lidar_84, lidar_85, lidar_86, lidar_87, lidar_88, lidar_89, lidar_90, lidar_91, lidar_92, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 376 columns]\n"
     ]
    }
   ],
   "source": [
    "# print rows with missing values\n",
    "print(df[df.isnull().any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch Dataset\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "class KULBarnDataset(Dataset):\n",
    "    def get_normalized_goal(self):\n",
    "        x = self.data['pos_x']\n",
    "        y = self.data['pos_y']\n",
    "        goal_x = self.data['goal_x']\n",
    "        goal_y = self.data['goal_y']\n",
    "        theta = self.data['pose_heading']\n",
    "        self.data['goal_x'] = np.cos(theta) * (goal_x - x) + np.sin(theta) * (goal_y - y)\n",
    "        self.data['goal_y'] = -np.sin(theta) * (goal_x - x) + np.cos(theta) * (goal_y - y)\n",
    "        # dist = np.sqrt(self.data['goal_x'] ** 2 + self.data['goal_y'] ** 2)\n",
    "        # self.data['goal_x'] /= dist\n",
    "        # self.data['goal_y'] /= dist\n",
    "    \n",
    "    def __init__(self, df, mode=\"train\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.data = df\n",
    "        self.get_normalized_goal()  \n",
    "        \n",
    "        # get all the column values that contain the word lidar\n",
    "        self.lidar_cols = [\"lidar_\" + str(i) for i in range(0, 360, 1)]\n",
    "        # get actions columns\n",
    "        self.actions_cols = ['cmd_vel_linear', 'cmd_vel_angular']\n",
    "        # get other columns\n",
    "        self.non_lidar_cols = ['local_goal_x', 'local_goal_y', 'goal_x', 'goal_y']\n",
    "\n",
    "        # if mode == \"train\":\n",
    "        #     # Manually compute the min and max values for each column\n",
    "        #     self.min = self.data.min()\n",
    "        #     self.max = self.data.max()\n",
    "        #     # Save the mean and std to a JSON file\n",
    "        #     scaler_params = {\n",
    "        #         'min': self.min.to_dict(),\n",
    "        #         'max': self.max.to_dict()\n",
    "        #     }\n",
    "        #     with open('scaler_params.json', 'w') as f:\n",
    "        #         json.dump(scaler_params, f)\n",
    "        # else:\n",
    "        #     # Load the mean and std from the JSON file\n",
    "        #     with open('scaler_params.json', 'r') as f:\n",
    "        #         scaler_params = json.load(f)\n",
    "        #     self.min = pd.Series(scaler_params['min'])\n",
    "        #     self.max = pd.Series(scaler_params['max'])\n",
    "        \n",
    "        # dont normalizer local_x and local_y\n",
    "        # self.normalized_data = (self.data - self.min) / (self.max - self.min)\n",
    "        self.normalized_data = self.data\n",
    "         \n",
    "        self.lidar_data = self.normalized_data[self.lidar_cols].values\n",
    "        self.non_lidar_data = self.normalized_data[self.non_lidar_cols].values\n",
    "        self.actions_data = self.normalized_data[self.actions_cols].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        lidar = self.lidar_data[idx]\n",
    "        non_lidar = self.non_lidar_data[idx]\n",
    "        actions = self.actions_data[idx]\n",
    "        return lidar, non_lidar, actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take random 90% of the world ids for training\n",
    "ids = df['world_idx'].unique()\n",
    "\n",
    "test_ids = list(range(0, 300, 5))\n",
    "\n",
    "non_test_ids = np.setdiff1d(ids, test_ids)\n",
    "\n",
    "train_ids = np.random.choice(non_test_ids, int(0.8 * len(non_test_ids)), replace=False)\n",
    "train_df = df[df['world_idx'].isin(train_ids)]\n",
    "train_dataset = KULBarnDataset(train_df, mode=\"train\")\n",
    "\n",
    "# take the remaining of the world ids for validation\n",
    "val_ids = np.setdiff1d(non_test_ids, train_ids)\n",
    "val_df = df[df['world_idx'].isin(val_ids)]\n",
    "val_dataset = KULBarnDataset(val_df, mode=\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192 48\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ids), len(val_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Length: 355482\n",
      "Val Dataset Length: 87520\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Dataset Length:\", len(train_dataset))\n",
    "print(\"Val Dataset Length:\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non lidar shape: torch.Size([64, 4])\n",
      "Lidar shape: torch.Size([64, 360])\n",
      "Train loader size: 5555\n",
      "Val loader size: 1368\n",
      "tensor([[4.1891, 4.2293, 5.0000,  ..., 5.0000, 5.0000, 5.0000],\n",
      "        [0.6376, 0.6520, 0.8003,  ..., 0.3954, 0.4083, 0.4211],\n",
      "        [5.0000, 5.0000, 5.0000,  ..., 3.9805, 3.9993, 4.0965],\n",
      "        ...,\n",
      "        [3.0564, 3.0413, 3.0458,  ..., 2.8291, 2.8346, 2.8672],\n",
      "        [3.0047, 2.9803, 2.9828,  ..., 2.8960, 2.9242, 2.9316],\n",
      "        [3.0983, 3.0469, 2.9917,  ..., 2.8137, 2.8703, 2.9022]],\n",
      "       dtype=torch.float64) tensor([[ 1.0094e+00, -4.4492e-02,  1.1990e+00, -7.9924e-02],\n",
      "        [ 9.3930e-01,  3.8028e-01,  3.5958e+00,  2.4351e+00],\n",
      "        [ 1.0061e+00,  1.0202e-02,  1.8343e+00,  1.0431e-01],\n",
      "        [ 1.0177e+00, -1.8371e-02,  2.3369e+00, -1.9387e-01],\n",
      "        [ 1.0185e+00,  3.2077e-02,  2.2539e+00,  1.5019e-01],\n",
      "        [ 1.0032e+00,  2.1043e-02,  2.2820e+00,  1.1016e-01],\n",
      "        [ 1.0026e+00, -2.2659e-02,  3.5433e+00, -3.0900e-01],\n",
      "        [-9.7709e-01, -2.2492e-01,  2.6640e+00, -5.4771e+00],\n",
      "        [ 9.9854e-01, -5.6612e-02,  9.2173e+00,  3.3361e-01],\n",
      "        [ 1.0184e+00,  1.4659e-02,  2.7448e+00,  2.2171e-01],\n",
      "        [ 9.9958e-01, -8.8092e-02,  9.9137e-01, -8.6597e-02],\n",
      "        [ 1.0240e+00,  4.5851e-02,  3.6500e+00, -3.4652e+00],\n",
      "        [ 8.6285e-01,  5.1121e-01,  3.8313e+00,  7.9192e+00],\n",
      "        [ 1.0179e+00,  6.1489e-02,  4.3167e+00,  3.4850e+00],\n",
      "        [ 1.0057e+00, -1.3711e-01,  8.9790e+00,  1.3266e+00],\n",
      "        [ 1.0063e+00, -5.2259e-02,  6.6643e+00,  5.3814e-01],\n",
      "        [ 1.0195e+00,  6.2493e-03,  3.1966e+00,  1.1808e-01],\n",
      "        [ 1.0186e+00, -6.8878e-02,  7.7500e+00, -1.5362e+00],\n",
      "        [ 9.4133e-01,  4.0064e-01,  4.5142e+00,  2.3179e+00],\n",
      "        [ 1.0028e+00, -1.0642e-01,  3.2846e+00, -6.1938e-01],\n",
      "        [ 1.0075e+00,  1.6751e-02,  6.5066e+00,  1.1884e-01],\n",
      "        [ 1.0179e+00,  5.5333e-02,  3.2717e+00,  3.2639e-01],\n",
      "        [ 1.0159e+00,  6.5639e-02,  5.8970e+00,  2.5563e+00],\n",
      "        [ 4.8855e-01,  8.8469e-01,  4.4998e+00,  4.9729e+00],\n",
      "        [ 1.0146e+00, -8.6550e-02,  4.6408e+00, -1.1822e+00],\n",
      "        [ 1.0218e+00, -8.4567e-03,  3.7076e+00, -3.3318e-01],\n",
      "        [ 1.0140e+00,  2.2268e-02,  2.0164e+00,  1.5597e-01],\n",
      "        [ 2.8561e-01,  9.7083e-01,  4.9291e+00, -2.5785e+00],\n",
      "        [ 1.0079e+00, -8.8053e-02,  7.7950e+00,  2.4770e+00],\n",
      "        [ 9.6516e-01, -3.2511e-01,  3.0950e+00, -1.5498e+00],\n",
      "        [ 1.0071e+00, -2.9152e-02,  1.5321e+00, -1.4271e-01],\n",
      "        [ 1.0082e+00, -4.7553e-02,  2.6898e+00, -2.8047e-01],\n",
      "        [ 1.0073e+00,  2.9667e-02,  7.3507e+00, -1.4604e+00],\n",
      "        [ 1.0139e+00,  3.5132e-02,  2.4419e+00,  1.8038e-01],\n",
      "        [ 1.0023e+00, -9.3100e-02,  9.6556e+00, -5.7841e-01],\n",
      "        [ 1.0229e+00, -1.4268e-02,  8.5282e+00,  2.4066e+00],\n",
      "        [ 9.8473e-01,  1.7743e-01,  9.0519e+00, -1.8285e+00],\n",
      "        [ 1.0104e+00, -2.4046e-02,  2.8940e+00, -3.4900e-01],\n",
      "        [ 1.0192e+00, -1.1096e-02,  2.4955e+00,  8.7785e-02],\n",
      "        [ 1.0222e+00, -6.5568e-02,  1.5785e+00, -1.6016e-01],\n",
      "        [ 1.0159e+00, -3.9195e-02,  3.0519e+00, -3.7657e-01],\n",
      "        [ 1.0046e+00, -1.0849e-01,  4.9410e+00,  1.0296e+00],\n",
      "        [ 8.9567e-01,  4.5724e-01,  2.1991e+00,  3.7209e+00],\n",
      "        [ 9.8493e-01, -1.8486e-01,  5.3243e+00, -2.6908e+00],\n",
      "        [ 1.0109e+00,  2.7520e-02,  2.0632e+00,  1.3427e-01],\n",
      "        [ 1.0182e+00, -8.6218e-02,  4.0784e+00, -7.7687e-01],\n",
      "        [ 1.0045e+00,  8.4007e-02,  6.8933e+00,  2.6962e-01],\n",
      "        [ 1.0121e+00,  8.0074e-02,  9.6171e+00,  1.3792e+00],\n",
      "        [ 9.7699e-01, -2.2789e-01,  2.8968e+00,  5.4829e+00],\n",
      "        [ 9.6725e-01, -3.1316e-01,  4.4607e+00,  8.0319e-01],\n",
      "        [ 1.0083e+00, -3.9310e-04,  4.2828e+00, -3.7655e-01],\n",
      "        [ 1.0104e+00,  1.0825e-01,  6.4011e+00, -3.7554e-01],\n",
      "        [ 1.0220e+00,  9.1860e-03,  1.1896e+00,  3.9913e-02],\n",
      "        [ 1.4020e-01,  1.0007e+00,  5.0563e+00,  3.0273e+00],\n",
      "        [ 1.0042e+00, -1.2693e-01,  5.9890e+00, -1.0301e+00],\n",
      "        [ 9.9919e-01, -5.8993e-02,  8.0129e+00, -2.5094e+00],\n",
      "        [ 6.5981e-01, -7.8397e-01,  6.0770e+00, -7.9399e+00],\n",
      "        [ 9.9641e-01,  1.5983e-01,  6.0724e+00,  1.0707e+00],\n",
      "        [ 1.0193e+00, -6.2557e-02,  4.8358e+00, -6.0874e-01],\n",
      "        [ 1.0006e+00, -1.3698e-01,  6.2660e+00,  7.8873e-01],\n",
      "        [ 1.0096e+00,  1.1145e-02,  3.5501e+00, -2.9931e-01],\n",
      "        [ 1.0072e+00,  4.3175e-03,  6.8809e+00,  1.2041e-01],\n",
      "        [ 9.8708e-01, -1.9604e-01,  6.4953e+00,  4.3447e-01],\n",
      "        [ 1.0215e+00, -6.0056e-02,  8.0889e+00,  8.3482e-01]],\n",
      "       dtype=torch.float64) tensor([[ 0.8000, -0.0765],\n",
      "        [ 0.8000,  0.2615],\n",
      "        [ 0.8000,  0.0209],\n",
      "        [ 0.8000, -0.0172],\n",
      "        [ 0.8000,  0.0555],\n",
      "        [ 0.8000,  0.0432],\n",
      "        [ 0.8000, -0.0241],\n",
      "        [-0.0000,  0.7500],\n",
      "        [ 0.8000, -0.1051],\n",
      "        [ 0.8000,  0.0651],\n",
      "        [ 0.8000, -0.1320],\n",
      "        [ 0.8000,  0.1333],\n",
      "        [ 0.8000,  0.8888],\n",
      "        [ 0.8000,  0.0838],\n",
      "        [ 0.8000, -0.2115],\n",
      "        [ 0.8000, -0.0634],\n",
      "        [ 0.8000,  0.0074],\n",
      "        [ 0.8000, -0.1102],\n",
      "        [ 0.8000,  0.8135],\n",
      "        [ 0.8000, -0.1738],\n",
      "        [ 0.8000,  0.0909],\n",
      "        [ 0.8000,  0.0976],\n",
      "        [ 0.8000, -0.0621],\n",
      "        [ 0.1700,  1.0982],\n",
      "        [ 0.8000, -0.1536],\n",
      "        [ 0.8000, -0.0072],\n",
      "        [ 0.8000,  0.0678],\n",
      "        [ 0.0500,  0.3853],\n",
      "        [ 0.8000, -0.1358],\n",
      "        [ 0.8000, -0.6265],\n",
      "        [ 0.8000, -0.0601],\n",
      "        [ 0.8000, -0.0708],\n",
      "        [ 0.8000,  0.0761],\n",
      "        [ 0.8000,  0.0491],\n",
      "        [ 0.8000, -0.1484],\n",
      "        [ 0.8000, -0.0049],\n",
      "        [ 0.8000,  0.3198],\n",
      "        [ 0.8000, -0.0163],\n",
      "        [ 0.8000, -0.0144],\n",
      "        [ 0.8000, -0.1033],\n",
      "        [ 0.8000, -0.0548],\n",
      "        [ 0.8000, -0.1571],\n",
      "        [ 0.8000,  0.2315],\n",
      "        [ 0.8000, -0.2683],\n",
      "        [ 0.8000,  0.0637],\n",
      "        [ 0.8000, -0.1211],\n",
      "        [ 0.8000,  0.1206],\n",
      "        [ 0.8000,  0.1626],\n",
      "        [ 0.0500, -0.0218],\n",
      "        [ 0.8000, -0.6164],\n",
      "        [ 0.8000,  0.0226],\n",
      "        [ 0.8000,  0.1813],\n",
      "        [ 0.8000,  0.0410],\n",
      "        [ 0.0500,  0.7394],\n",
      "        [ 0.8000, -0.2142],\n",
      "        [ 0.8000, -0.0403],\n",
      "        [ 0.1200, -0.1627],\n",
      "        [ 0.8000,  0.2731],\n",
      "        [ 0.8000, -0.1003],\n",
      "        [ 0.8000, -0.2199],\n",
      "        [ 0.8000,  0.0321],\n",
      "        [ 0.8000,  0.0063],\n",
      "        [ 0.8000, -0.2487],\n",
      "        [ 0.8000, -0.0805]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "# test dataloader\n",
    "lidar, non_lidar, actions = next(iter(train_loader))\n",
    "print(f\"Non lidar shape: {non_lidar.shape}\")\n",
    "print(f\"Lidar shape: {lidar.shape}\")\n",
    "# print size dataloader\n",
    "print(f\"Train loader size: {len(train_loader)}\")\n",
    "print(f\"Val loader size: {len(val_loader)}\")\n",
    "print(lidar, non_lidar, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.1891, 4.2293, 5.0000,  ..., 5.0000, 5.0000, 5.0000],\n",
       "        [0.6376, 0.6520, 0.8003,  ..., 0.3954, 0.4083, 0.4211],\n",
       "        [5.0000, 5.0000, 5.0000,  ..., 3.9805, 3.9993, 4.0965],\n",
       "        ...,\n",
       "        [3.0564, 3.0413, 3.0458,  ..., 2.8291, 2.8346, 2.8672],\n",
       "        [3.0047, 2.9803, 2.9828,  ..., 2.8960, 2.9242, 2.9316],\n",
       "        [3.0983, 3.0469, 2.9917,  ..., 2.8137, 2.8703, 2.9022]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lidar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0094e+00, -4.4492e-02,  1.1990e+00, -7.9924e-02],\n",
       "        [ 9.3930e-01,  3.8028e-01,  3.5958e+00,  2.4351e+00],\n",
       "        [ 1.0061e+00,  1.0202e-02,  1.8343e+00,  1.0431e-01],\n",
       "        [ 1.0177e+00, -1.8371e-02,  2.3369e+00, -1.9387e-01],\n",
       "        [ 1.0185e+00,  3.2077e-02,  2.2539e+00,  1.5019e-01],\n",
       "        [ 1.0032e+00,  2.1043e-02,  2.2820e+00,  1.1016e-01],\n",
       "        [ 1.0026e+00, -2.2659e-02,  3.5433e+00, -3.0900e-01],\n",
       "        [-9.7709e-01, -2.2492e-01,  2.6640e+00, -5.4771e+00],\n",
       "        [ 9.9854e-01, -5.6612e-02,  9.2173e+00,  3.3361e-01],\n",
       "        [ 1.0184e+00,  1.4659e-02,  2.7448e+00,  2.2171e-01],\n",
       "        [ 9.9958e-01, -8.8092e-02,  9.9137e-01, -8.6597e-02],\n",
       "        [ 1.0240e+00,  4.5851e-02,  3.6500e+00, -3.4652e+00],\n",
       "        [ 8.6285e-01,  5.1121e-01,  3.8313e+00,  7.9192e+00],\n",
       "        [ 1.0179e+00,  6.1489e-02,  4.3167e+00,  3.4850e+00],\n",
       "        [ 1.0057e+00, -1.3711e-01,  8.9790e+00,  1.3266e+00],\n",
       "        [ 1.0063e+00, -5.2259e-02,  6.6643e+00,  5.3814e-01],\n",
       "        [ 1.0195e+00,  6.2493e-03,  3.1966e+00,  1.1808e-01],\n",
       "        [ 1.0186e+00, -6.8878e-02,  7.7500e+00, -1.5362e+00],\n",
       "        [ 9.4133e-01,  4.0064e-01,  4.5142e+00,  2.3179e+00],\n",
       "        [ 1.0028e+00, -1.0642e-01,  3.2846e+00, -6.1938e-01],\n",
       "        [ 1.0075e+00,  1.6751e-02,  6.5066e+00,  1.1884e-01],\n",
       "        [ 1.0179e+00,  5.5333e-02,  3.2717e+00,  3.2639e-01],\n",
       "        [ 1.0159e+00,  6.5639e-02,  5.8970e+00,  2.5563e+00],\n",
       "        [ 4.8855e-01,  8.8469e-01,  4.4998e+00,  4.9729e+00],\n",
       "        [ 1.0146e+00, -8.6550e-02,  4.6408e+00, -1.1822e+00],\n",
       "        [ 1.0218e+00, -8.4567e-03,  3.7076e+00, -3.3318e-01],\n",
       "        [ 1.0140e+00,  2.2268e-02,  2.0164e+00,  1.5597e-01],\n",
       "        [ 2.8561e-01,  9.7083e-01,  4.9291e+00, -2.5785e+00],\n",
       "        [ 1.0079e+00, -8.8053e-02,  7.7950e+00,  2.4770e+00],\n",
       "        [ 9.6516e-01, -3.2511e-01,  3.0950e+00, -1.5498e+00],\n",
       "        [ 1.0071e+00, -2.9152e-02,  1.5321e+00, -1.4271e-01],\n",
       "        [ 1.0082e+00, -4.7553e-02,  2.6898e+00, -2.8047e-01],\n",
       "        [ 1.0073e+00,  2.9667e-02,  7.3507e+00, -1.4604e+00],\n",
       "        [ 1.0139e+00,  3.5132e-02,  2.4419e+00,  1.8038e-01],\n",
       "        [ 1.0023e+00, -9.3100e-02,  9.6556e+00, -5.7841e-01],\n",
       "        [ 1.0229e+00, -1.4268e-02,  8.5282e+00,  2.4066e+00],\n",
       "        [ 9.8473e-01,  1.7743e-01,  9.0519e+00, -1.8285e+00],\n",
       "        [ 1.0104e+00, -2.4046e-02,  2.8940e+00, -3.4900e-01],\n",
       "        [ 1.0192e+00, -1.1096e-02,  2.4955e+00,  8.7785e-02],\n",
       "        [ 1.0222e+00, -6.5568e-02,  1.5785e+00, -1.6016e-01],\n",
       "        [ 1.0159e+00, -3.9195e-02,  3.0519e+00, -3.7657e-01],\n",
       "        [ 1.0046e+00, -1.0849e-01,  4.9410e+00,  1.0296e+00],\n",
       "        [ 8.9567e-01,  4.5724e-01,  2.1991e+00,  3.7209e+00],\n",
       "        [ 9.8493e-01, -1.8486e-01,  5.3243e+00, -2.6908e+00],\n",
       "        [ 1.0109e+00,  2.7520e-02,  2.0632e+00,  1.3427e-01],\n",
       "        [ 1.0182e+00, -8.6218e-02,  4.0784e+00, -7.7687e-01],\n",
       "        [ 1.0045e+00,  8.4007e-02,  6.8933e+00,  2.6962e-01],\n",
       "        [ 1.0121e+00,  8.0074e-02,  9.6171e+00,  1.3792e+00],\n",
       "        [ 9.7699e-01, -2.2789e-01,  2.8968e+00,  5.4829e+00],\n",
       "        [ 9.6725e-01, -3.1316e-01,  4.4607e+00,  8.0319e-01],\n",
       "        [ 1.0083e+00, -3.9310e-04,  4.2828e+00, -3.7655e-01],\n",
       "        [ 1.0104e+00,  1.0825e-01,  6.4011e+00, -3.7554e-01],\n",
       "        [ 1.0220e+00,  9.1860e-03,  1.1896e+00,  3.9913e-02],\n",
       "        [ 1.4020e-01,  1.0007e+00,  5.0563e+00,  3.0273e+00],\n",
       "        [ 1.0042e+00, -1.2693e-01,  5.9890e+00, -1.0301e+00],\n",
       "        [ 9.9919e-01, -5.8993e-02,  8.0129e+00, -2.5094e+00],\n",
       "        [ 6.5981e-01, -7.8397e-01,  6.0770e+00, -7.9399e+00],\n",
       "        [ 9.9641e-01,  1.5983e-01,  6.0724e+00,  1.0707e+00],\n",
       "        [ 1.0193e+00, -6.2557e-02,  4.8358e+00, -6.0874e-01],\n",
       "        [ 1.0006e+00, -1.3698e-01,  6.2660e+00,  7.8873e-01],\n",
       "        [ 1.0096e+00,  1.1145e-02,  3.5501e+00, -2.9931e-01],\n",
       "        [ 1.0072e+00,  4.3175e-03,  6.8809e+00,  1.2041e-01],\n",
       "        [ 9.8708e-01, -1.9604e-01,  6.4953e+00,  4.3447e-01],\n",
       "        [ 1.0215e+00, -6.0056e-02,  8.0889e+00,  8.3482e-01]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_lidar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8000, -0.0765],\n",
       "        [ 0.8000,  0.2615],\n",
       "        [ 0.8000,  0.0209],\n",
       "        [ 0.8000, -0.0172],\n",
       "        [ 0.8000,  0.0555],\n",
       "        [ 0.8000,  0.0432],\n",
       "        [ 0.8000, -0.0241],\n",
       "        [-0.0000,  0.7500],\n",
       "        [ 0.8000, -0.1051],\n",
       "        [ 0.8000,  0.0651],\n",
       "        [ 0.8000, -0.1320],\n",
       "        [ 0.8000,  0.1333],\n",
       "        [ 0.8000,  0.8888],\n",
       "        [ 0.8000,  0.0838],\n",
       "        [ 0.8000, -0.2115],\n",
       "        [ 0.8000, -0.0634],\n",
       "        [ 0.8000,  0.0074],\n",
       "        [ 0.8000, -0.1102],\n",
       "        [ 0.8000,  0.8135],\n",
       "        [ 0.8000, -0.1738],\n",
       "        [ 0.8000,  0.0909],\n",
       "        [ 0.8000,  0.0976],\n",
       "        [ 0.8000, -0.0621],\n",
       "        [ 0.1700,  1.0982],\n",
       "        [ 0.8000, -0.1536],\n",
       "        [ 0.8000, -0.0072],\n",
       "        [ 0.8000,  0.0678],\n",
       "        [ 0.0500,  0.3853],\n",
       "        [ 0.8000, -0.1358],\n",
       "        [ 0.8000, -0.6265],\n",
       "        [ 0.8000, -0.0601],\n",
       "        [ 0.8000, -0.0708],\n",
       "        [ 0.8000,  0.0761],\n",
       "        [ 0.8000,  0.0491],\n",
       "        [ 0.8000, -0.1484],\n",
       "        [ 0.8000, -0.0049],\n",
       "        [ 0.8000,  0.3198],\n",
       "        [ 0.8000, -0.0163],\n",
       "        [ 0.8000, -0.0144],\n",
       "        [ 0.8000, -0.1033],\n",
       "        [ 0.8000, -0.0548],\n",
       "        [ 0.8000, -0.1571],\n",
       "        [ 0.8000,  0.2315],\n",
       "        [ 0.8000, -0.2683],\n",
       "        [ 0.8000,  0.0637],\n",
       "        [ 0.8000, -0.1211],\n",
       "        [ 0.8000,  0.1206],\n",
       "        [ 0.8000,  0.1626],\n",
       "        [ 0.0500, -0.0218],\n",
       "        [ 0.8000, -0.6164],\n",
       "        [ 0.8000,  0.0226],\n",
       "        [ 0.8000,  0.1813],\n",
       "        [ 0.8000,  0.0410],\n",
       "        [ 0.0500,  0.7394],\n",
       "        [ 0.8000, -0.2142],\n",
       "        [ 0.8000, -0.0403],\n",
       "        [ 0.1200, -0.1627],\n",
       "        [ 0.8000,  0.2731],\n",
       "        [ 0.8000, -0.1003],\n",
       "        [ 0.8000, -0.2199],\n",
       "        [ 0.8000,  0.0321],\n",
       "        [ 0.8000,  0.0063],\n",
       "        [ 0.8000, -0.2487],\n",
       "        [ 0.8000, -0.0805]], dtype=torch.float64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_lidar_features, num_non_lidar_features, num_actions, nframes=1):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.act_fea_cv1 = nn.Conv1d(\n",
    "            in_channels=nframes, out_channels=32, kernel_size=5, stride=2, padding=6, padding_mode='circular'\n",
    "        )\n",
    "        self.act_fea_cv2 = nn.Conv1d(\n",
    "            in_channels=32, out_channels=32, kernel_size=3, stride=2, padding=1\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            sample_input = torch.randn(1, nframes, num_lidar_features)\n",
    "            sample_output = self.act_fea_cv1(sample_input)\n",
    "            sample_output = self.act_fea_cv2(sample_output)\n",
    "            conv_output_size = sample_output.view(1, -1).shape[1]\n",
    "\n",
    "        # Calculate the output size of the CNN\n",
    "        self.fc1 = nn.Linear(conv_output_size, 64)\n",
    "        self.fc2 = nn.Linear(64 + num_non_lidar_features * nframes, 64)\n",
    "        self.fc3 = nn.Linear(64, num_actions)\n",
    "\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "\n",
    "    def forward(self, lidar, non_lidar):\n",
    "        feat = F.relu(self.act_fea_cv1(lidar))\n",
    "        feat = F.relu(self.act_fea_cv2(feat))\n",
    "        feat = feat.view(feat.shape[0], -1)\n",
    "        feat = F.relu(self.fc1(feat))\n",
    "        # feat = torch.cat((feat, non_lidar.view(non_lidar.shape[0], -1)), dim=-1)\n",
    "        feat = torch.cat((feat, non_lidar.flatten(start_dim=1)), dim=-1)\n",
    "        feat = F.relu(self.fc2(feat))\n",
    "        feat = self.fc3(feat)\n",
    "        return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a CustomLoss prioritizing the angular velocity\n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        # increase the loss of the second element of the prediction\n",
    "        # this is the angular velocity\n",
    "        loss = (pred - target) ** 2\n",
    "        loss[:, 1] *= 2\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "num_lidar_features = len(train_dataset.lidar_cols)\n",
    "num_non_lidar_features = len(train_dataset.non_lidar_cols)\n",
    "num_actions = len(train_dataset.actions_cols)\n",
    "model = CNNModel(num_lidar_features, num_non_lidar_features, num_actions)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Move the model and loss function to the GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "loss_fn = loss_fn.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, train_loader, loss_fn, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    for lidar, non_lidar, actions in tqdm(train_loader):\n",
    "        # Move the data to the device that is used\n",
    "        lidar = lidar.to(device).unsqueeze(1)\n",
    "        non_lidar = non_lidar.to(device).unsqueeze(1)\n",
    "        actions = actions.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        actions_pred = model(lidar.float(), non_lidar.float())\n",
    "        loss = loss_fn(actions_pred, actions.float())\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Save the loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # return the average loss for this epoch\n",
    "    return sum(losses)/len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, loss_fn):\n",
    "    model.eval()\n",
    "\n",
    "    losses = []\n",
    "    for lidar, non_lidar, actions in tqdm(test_loader):\n",
    "        # Move the data to the device that is used\n",
    "        lidar = lidar.to(device).unsqueeze(1)\n",
    "        non_lidar = non_lidar.to(device).unsqueeze(1)\n",
    "        actions = actions.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        actions_pred = model(lidar.float(), non_lidar.float())\n",
    "        loss = loss_fn(actions_pred, actions.float())\n",
    "\n",
    "        # Save the loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # return the average loss for this epoch\n",
    "    return sum(losses)/len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# NUM_EPOCHS = 50\n",
    "\n",
    "# random_val_loss = test_model(model, val_loader, loss_fn)\n",
    "# print(\"Random val loss:\", random_val_loss)\n",
    "# sys.stdout.flush()\n",
    "\n",
    "# cnn_train_losses = []\n",
    "# cnn_val_losses = []\n",
    "# best_val_loss = float('inf')\n",
    "# patience = 3\n",
    "# no_improve_epochs = 0\n",
    "\n",
    "# for epoch in range(NUM_EPOCHS):\n",
    "#     train_loss = train_model(model, train_loader, loss_fn, optimizer)\n",
    "#     val_loss = test_model(model, val_loader, loss_fn)\n",
    "#     cnn_train_losses.append(train_loss)\n",
    "#     cnn_val_losses.append(val_loss)\n",
    "#     print(f\"Epoch {epoch+1}/{NUM_EPOCHS} | Train Loss: {train_loss} | Val Loss: {val_loss}\")\n",
    "#     sys.stdout.flush()\n",
    "\n",
    "#     # Early stopping\n",
    "#     if val_loss < best_val_loss:\n",
    "#         best_val_loss = val_loss\n",
    "#         no_improve_epochs = 0\n",
    "#     else:\n",
    "#         no_improve_epochs += 1\n",
    "#         if no_improve_epochs >= patience:\n",
    "#             print(\"Early stopping due to no improvement after {} epochs.\".format(patience))\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the loss\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(cnn_train_losses, label='Train Loss')\n",
    "# plt.plot(cnn_val_losses, label='Val Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "# torch.save(model.state_dict(), 'cnn_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, loss_fn):\n",
    "    model.eval()\n",
    "\n",
    "    losses = []\n",
    "    for lidar, non_lidar, actions in tqdm(test_loader):\n",
    "        # Move the data to the device that is used\n",
    "        lidar = lidar.to(device).unsqueeze(1)\n",
    "        non_lidar = non_lidar.to(device).unsqueeze(1)\n",
    "        actions = actions.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        actions_pred = model(lidar.float(), non_lidar.float())\n",
    "        loss = loss_fn(actions_pred, actions.float())\n",
    "\n",
    "        if loss.item() > 0.1:\n",
    "            print(\"---------------------------\")\n",
    "            print(\"Loss:\", loss.item())\n",
    "            print(\"Predicted:\", actions_pred)\n",
    "            print(\"Actual:\", actions)\n",
    "            print(\"Non lidar:\", non_lidar)\n",
    "            continue\n",
    "\n",
    "        # Save the loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # return the average loss for this epoch\n",
    "    return sum(losses)/len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–Œ        | 269/1789 [00:00<00:01, 1436.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Loss: 0.17604592442512512\n",
      "Predicted: tensor([[0.6789, 0.0863]], grad_fn=<AddmmBackward0>)\n",
      "Actual: tensor([[0.0900, 0.0139]], dtype=torch.float64)\n",
      "Non lidar: tensor([[[0.9975, 0.0734, 9.9962, 0.2351]]], dtype=torch.float64)\n",
      "---------------------------\n",
      "Loss: 0.16187474131584167\n",
      "Predicted: tensor([[0.6853, 0.0833]], grad_fn=<AddmmBackward0>)\n",
      "Actual: tensor([[0.1200, 0.0186]], dtype=torch.float64)\n",
      "Non lidar: tensor([[[1.0212, 0.0739, 9.9949, 0.2343]]], dtype=torch.float64)\n",
      "---------------------------\n",
      "Loss: 0.14499592781066895\n",
      "Predicted: tensor([[0.6851, 0.0839]], grad_fn=<AddmmBackward0>)\n",
      "Actual: tensor([[0.1500, 0.0232]], dtype=torch.float64)\n",
      "Non lidar: tensor([[[1.0192, 0.0739, 9.9929, 0.2339]]], dtype=torch.float64)\n",
      "---------------------------\n",
      "Loss: 0.13023898005485535\n",
      "Predicted: tensor([[0.6850, 0.0851]], grad_fn=<AddmmBackward0>)\n",
      "Actual: tensor([[0.1800, 0.0112]], dtype=torch.float64)\n",
      "Non lidar: tensor([[[1.0166, 0.0738, 9.9903, 0.2326]]], dtype=torch.float64)\n",
      "---------------------------\n",
      "Loss: 0.11513453722000122\n",
      "Predicted: tensor([[0.6843, 0.0859]], grad_fn=<AddmmBackward0>)\n",
      "Actual: tensor([[0.2100, 0.0130]], dtype=torch.float64)\n",
      "Non lidar: tensor([[[1.0134, 0.0737, 9.9871, 0.2320]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1789/1789 [00:00<00:00, 2182.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Loss: 0.16021324694156647\n",
      "Predicted: tensor([[0.7408, 0.1175]], grad_fn=<AddmmBackward0>)\n",
      "Actual: tensor([[0.1800, 0.0403]], dtype=torch.float64)\n",
      "Non lidar: tensor([[[1.0119, 0.1120, 9.9331, 1.0930]]], dtype=torch.float64)\n",
      "---------------------------\n",
      "Loss: 0.14282071590423584\n",
      "Predicted: tensor([[0.7399, 0.1170]], grad_fn=<AddmmBackward0>)\n",
      "Actual: tensor([[0.2100, 0.0470]], dtype=torch.float64)\n",
      "Non lidar: tensor([[[1.0088, 0.1116, 9.9304, 1.0889]]], dtype=torch.float64)\n",
      "---------------------------\n",
      "Loss: 0.12632997334003448\n",
      "Predicted: tensor([[0.7388, 0.1160]], grad_fn=<AddmmBackward0>)\n",
      "Actual: tensor([[0.2400, 0.0537]], dtype=torch.float64)\n",
      "Non lidar: tensor([[[1.0051, 0.1109, 9.9274, 1.0827]]], dtype=torch.float64)\n",
      "---------------------------\n",
      "Loss: 0.11394906789064407\n",
      "Predicted: tensor([[0.7442, 0.1157]], grad_fn=<AddmmBackward0>)\n",
      "Actual: tensor([[0.2700, 0.0605]], dtype=torch.float64)\n",
      "Non lidar: tensor([[[1.0009, 0.1103, 9.9237, 1.0763]]], dtype=torch.float64)\n",
      "Final val loss: 0.003381158567652175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load file and check MSELoss\n",
    "model = CNNModel(num_lidar_features, num_non_lidar_features, num_actions)\n",
    "model.load_state_dict(torch.load('cnn_model.pth', map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "device = 'cpu'\n",
    "\n",
    "# take world idx 0 as example\n",
    "dataset = KULBarnDataset(df[df['world_idx'] == 0], \"val\")\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "final_val_loss = test_model(model, loader, loss_fn)\n",
    "print(\"Final val loss:\", final_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_dim,\n",
    "            num_heads,\n",
    "            dropout=0.0,\n",
    "            bias=False,\n",
    "            encoder_decoder_attention=False,\n",
    "            causal=False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        self.head_dim = input_dim // num_heads\n",
    "        self.encoder_decoder_attention = encoder_decoder_attention\n",
    "        self.causal = causal\n",
    "        self.k_proj = nn.Linear(input_dim, input_dim, bias=bias)\n",
    "        self.v_proj = nn.Linear(input_dim, input_dim, bias=bias)\n",
    "        self.q_proj = nn.Linear(input_dim, input_dim, bias=bias)\n",
    "        self.out_proj = nn.Linear(input_dim, input_dim, bias=bias)\n",
    "\n",
    "    def transpose_for_scores(self, x):\n",
    "        new_x_shape = x.size()[:-1] + (self.num_heads, self.head_dim,)\n",
    "        x = x.view(*new_x_shape)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "\n",
    "    def multi_head_scaled_dot_product(self,\n",
    "                                      query: torch.Tensor,\n",
    "                                      key: torch.Tensor,\n",
    "                                      value: torch.Tensor,\n",
    "                                      attention_mask: torch.BoolTensor):\n",
    "        attn_weights = torch.matmul(query, key.transpose(-1, -2) / math.sqrt(self.input_dim))\n",
    "        if attention_mask is not None:\n",
    "            if self.causal:\n",
    "                attn_weights = attn_weights.masked_fill(attention_mask.unsqueeze(0).unsqueeze(1), float(\"-inf\"))\n",
    "            else:\n",
    "                attn_weights = attn_weights.masked_fill(attention_mask.unsqueeze(1).unsqueeze(2), float(\"-inf\"))\n",
    "        attn_weights = F.softmax(attn_weights, dim=-1)\n",
    "        attn_probs = F.dropout(attn_weights, p=self.dropout, training=self.training)\n",
    "        attn_output = torch.matmul(attn_probs, value)\n",
    "        attn_output = attn_output.permute(0, 2, 1, 3).contiguous()\n",
    "        concat_attn_output_shape = attn_output.size()[:-2] + (self.input_dim,)\n",
    "        attn_output = attn_output.view(*concat_attn_output_shape)\n",
    "        attn_output = self.out_proj(attn_output)\n",
    "        return attn_output, attn_weights\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            query: torch.Tensor,\n",
    "            key: torch.Tensor,\n",
    "            attention_mask: torch.BoolTensor):\n",
    "        q = self.q_proj(query)\n",
    "        if self.encoder_decoder_attention:\n",
    "            k = self.k_proj(key)\n",
    "            v = self.v_proj(key)\n",
    "        else:\n",
    "            k = self.k_proj(query)\n",
    "            v = self.v_proj(query)\n",
    "        q = self.transpose_for_scores(q)\n",
    "        k = self.transpose_for_scores(k)\n",
    "        v = self.transpose_for_scores(v)\n",
    "\n",
    "        attn_output, attn_weights = self.multi_head_scaled_dot_product(q, k, v, attention_mask)\n",
    "        return attn_output, attn_weights\n",
    "\n",
    "\n",
    "class PositionWiseFeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim: int, d_ff: int, dropout: float = 0.1):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        self.w_1 = nn.Linear(input_dim, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, input_dim)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.activation(self.w_1(x))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.w_2(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        return x + residual\n",
    "\n",
    "\n",
    "class EmbeddingLidar(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.len_lidar = config.lidar_dim\n",
    "        self.num_patch = config.num_patch\n",
    "        self.dim_patch = self.len_lidar // self.num_patch\n",
    "        self.model_dim = config.model_dim\n",
    "        self.dropout = config.dropout\n",
    "        self.pos_embed = nn.Parameter(torch.randn(self.num_patch, self.model_dim))\n",
    "\n",
    "        self.linear = nn.Linear(self.dim_patch, self.model_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = inputs.view([-1, self.num_patch, self.dim_patch])\n",
    "        x = self.linear(x)\n",
    "        x = x + self.pos_embed\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.input_dim = config.input_dim\n",
    "        self.ffn_dim = config.ffn_dim\n",
    "        self.self_attn = MultiHeadAttention(\n",
    "            input_dim=self.input_dim,\n",
    "            num_heads=config.attention_heads,\n",
    "            dropout=config.attention_dropout)\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(self.input_dim)\n",
    "        self.dropout = config.dropout\n",
    "        self.activation_fn = nn.ReLU()\n",
    "        self.PositionWiseFeedForward = PositionWiseFeedForward(self.input_dim, self.ffn_dim, config.dropout)\n",
    "        self.final_layer_norm = nn.LayerNorm(self.input_dim)\n",
    "\n",
    "    def forward(self, x, encoder_padding_mask):\n",
    "        residual = x\n",
    "        x, attn_weights = self.self_attn(query=x, key=x, attention_mask=encoder_padding_mask)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = residual + x\n",
    "        x = self.self_attn_layer_norm(x)\n",
    "        x = self.PositionWiseFeedForward(x)\n",
    "        x = self.final_layer_norm(x)\n",
    "        return x, attn_weights\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dropout = config.dropout\n",
    "\n",
    "        self.embedding = EmbeddingLidar(config)\n",
    "\n",
    "        self.layers = nn.ModuleList([EncoderLayer(config) for _ in range(config.encoder_layers)])\n",
    "\n",
    "    def forward(self, inputs, attention_mask=None):\n",
    "        x = self.embedding(inputs)\n",
    "        self_attn_scores = []\n",
    "        for encoder_layer in self.layers:\n",
    "            x, attn = encoder_layer(x, attention_mask)\n",
    "            self_attn_scores.append(attn.detach())\n",
    "\n",
    "        return x, self_attn_scores\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.input_dim = config.input_dim\n",
    "        self.ffn_dim = config.ffn_dim\n",
    "        self.dropout = config.dropout\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(self.input_dim)\n",
    "        self.encoder_attn = MultiHeadAttention(\n",
    "            input_dim=self.input_dim,\n",
    "            num_heads=config.attention_heads,\n",
    "            dropout=config.attention_dropout,\n",
    "            encoder_decoder_attention=True,\n",
    "        )\n",
    "        self.encoder_attn_layer_norm = nn.LayerNorm(self.input_dim)\n",
    "        self.PositionWiseFeedForward = PositionWiseFeedForward(self.input_dim, self.ffn_dim, config.dropout)\n",
    "        self.final_layer_norm = nn.LayerNorm(self.input_dim)\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            x,\n",
    "            encoder_hidden_states,\n",
    "            encoder_attention_mask=None,\n",
    "    ):\n",
    "        residual = x\n",
    "        x, cross_attn_weights = self.encoder_attn(\n",
    "            query=x,\n",
    "            key=encoder_hidden_states,\n",
    "            attention_mask=encoder_attention_mask,\n",
    "        )\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = residual + x\n",
    "        x = self.encoder_attn_layer_norm(x)\n",
    "        x = self.PositionWiseFeedForward(x)\n",
    "        x = self.final_layer_norm(x)\n",
    "\n",
    "        return (\n",
    "            x,\n",
    "            cross_attn_weights,\n",
    "        )\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dropout = config.dropout\n",
    "        self.model_dim = config.model_dim\n",
    "        self.linear = nn.Linear(1, self.model_dim)\n",
    "        self.layers = nn.ModuleList([DecoderLayer(config) for _ in range(config.decoder_layers)])\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            inputs,\n",
    "            encoder_hidden_states,\n",
    "    ):\n",
    "        x = inputs\n",
    "        x = self.linear(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        cross_attention_scores = []\n",
    "        for idx, decoder_layer in enumerate(self.layers):\n",
    "            x, layer_cross_attn = decoder_layer(\n",
    "                x,\n",
    "                encoder_hidden_states,\n",
    "            )\n",
    "            cross_attention_scores.append(layer_cross_attn.detach())\n",
    "        return x, cross_attention_scores\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.non_lidar_dim = config.non_lidar_dim\n",
    "        self.model_dim = config.model_dim\n",
    "        self.encoder = Encoder(config)\n",
    "        self.decoder = Decoder(config)\n",
    "\n",
    "        self.prediction_head = nn.Linear(self.model_dim * self.non_lidar_dim, 2)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                if 'weight' in name:\n",
    "                    nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "                else:\n",
    "                    nn.init.constant_(param.data, 0)\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        encoder_output, encoder_attention_scores = self.encoder(\n",
    "            inputs=src\n",
    "        )\n",
    "        decoder_output, decoder_attention_scores = self.decoder(\n",
    "            trg,\n",
    "            encoder_output\n",
    "        )\n",
    "        decoder_output = decoder_output.view(-1, self.model_dim * self.non_lidar_dim)\n",
    "        decoder_output = self.prediction_head(decoder_output)\n",
    "        \n",
    "        return decoder_output, encoder_attention_scores, decoder_attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, loss_fn, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    for lidar, non_lidar, actions in tqdm(train_loader):\n",
    "        lidar = lidar.to(device).unsqueeze(-1)\n",
    "        non_lidar = non_lidar.to(device).unsqueeze(-1)\n",
    "        actions = actions.to(device)\n",
    "\n",
    "        actions_pred, _, _ = model(lidar.float(), non_lidar.float())\n",
    "        loss = loss_fn(actions_pred, actions.float())\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Save the loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # return the average loss for this epoch\n",
    "    return sum(losses)/len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, loss_fn):\n",
    "    model.eval()\n",
    "\n",
    "    losses = []\n",
    "    for lidar, non_lidar, actions in tqdm(test_loader):\n",
    "        lidar = lidar.to(device).unsqueeze(-1)\n",
    "        non_lidar = non_lidar.to(device).unsqueeze(-1)\n",
    "        actions = actions.to(device)\n",
    "\n",
    "        actions_pred, _, _ = model(lidar.float(), non_lidar.float())\n",
    "\n",
    "        loss = loss_fn(actions_pred, actions.float())\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # return the average loss for this epoch\n",
    "    return sum(losses)/len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import easydict\n",
    "\n",
    "# Initialize the model\n",
    "num_lidar_features = len(train_dataset.lidar_cols)\n",
    "num_non_lidar_features = len(train_dataset.non_lidar_cols)\n",
    "num_actions = len(train_dataset.actions_cols)\n",
    "\n",
    "config_dict = easydict.EasyDict({\n",
    "    \"input_dim\": 32,\n",
    "    \"num_patch\": 36,\n",
    "    \"model_dim\": 32,\n",
    "    \"ffn_dim\": 256,\n",
    "    \"attention_heads\": 4,\n",
    "    \"attention_dropout\": 0.0,\n",
    "    \"dropout\": 0.5,\n",
    "    \"encoder_layers\": 2,\n",
    "    \"decoder_layers\": 2,\n",
    "    \"lidar_dim\": 360,\n",
    "    \"non_lidar_dim\": 4,\n",
    "    \"device\": \"cpu\",\n",
    "})\n",
    "\n",
    "model = Transformer(config_dict)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Move the model and loss function to the GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "loss_fn = loss_fn.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1368/1368 [00:06<00:00, 213.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random val loss: 0.3530645494115109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5555/5555 [00:54<00:00, 101.64it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1368/1368 [00:04<00:00, 284.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 | Train Loss: 0.15075266739801177 | Val Loss: 0.04009330039815196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5555/5555 [00:52<00:00, 105.93it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1368/1368 [00:05<00:00, 257.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 | Train Loss: 0.03643872657343142 | Val Loss: 0.026557865125125733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5555/5555 [00:53<00:00, 104.68it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1368/1368 [00:04<00:00, 280.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 | Train Loss: 0.025288012791986635 | Val Loss: 0.018639434487002886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5555/5555 [00:50<00:00, 109.16it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1368/1368 [00:05<00:00, 252.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 | Train Loss: 0.01986906429665527 | Val Loss: 0.015296926806226302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5555/5555 [00:54<00:00, 102.76it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1368/1368 [00:04<00:00, 276.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 | Train Loss: 0.018088555732900385 | Val Loss: 0.01370929466029019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5555/5555 [00:48<00:00, 113.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1368/1368 [00:04<00:00, 285.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 | Train Loss: 0.01745991376872006 | Val Loss: 0.013421671791904203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5555/5555 [00:49<00:00, 112.60it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1368/1368 [00:04<00:00, 287.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 | Train Loss: 0.017141110411049626 | Val Loss: 0.013083743458279399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5555/5555 [00:48<00:00, 114.46it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1368/1368 [00:04<00:00, 284.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 | Train Loss: 0.016919055868222687 | Val Loss: 0.013583069413093467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5555/5555 [00:48<00:00, 114.11it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1368/1368 [00:04<00:00, 277.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 | Train Loss: 0.016740585925957837 | Val Loss: 0.014288075304031407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5555/5555 [00:48<00:00, 115.02it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1368/1368 [00:05<00:00, 271.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 | Train Loss: 0.016539022758578787 | Val Loss: 0.013506586282809414\n",
      "Early stopping due to no improvement after 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "random_val_loss = test_model(model, val_loader, loss_fn)\n",
    "print(\"Random val loss:\", random_val_loss)\n",
    "\n",
    "transformer_train_losses = []\n",
    "transformer_val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "patience = 3\n",
    "no_improve_epochs = 0\n",
    "save_every = 5\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    train_loss = train_model(model, train_loader, loss_fn, optimizer)\n",
    "    val_loss = test_model(model, val_loader, loss_fn)\n",
    "    transformer_train_losses.append(train_loss)\n",
    "    transformer_val_losses.append(val_loss)\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} | Train Loss: {train_loss} | Val Loss: {val_loss}\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        no_improve_epochs = 0\n",
    "    else:\n",
    "        no_improve_epochs += 1\n",
    "        if no_improve_epochs >= patience:\n",
    "            print(\"Early stopping due to no improvement after {} epochs.\".format(patience))\n",
    "            break\n",
    "    \n",
    "    # if epoch % save_every == 0:\n",
    "    #     torch.save(model.state_dict(), f'transformer_model_{epoch}.pth')\n",
    "    #     print(f\"Model saved at epoch {epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(transformer_train_losses, label='Transformer Train Loss')  \n",
    "plt.plot(transformer_val_losses, label='Transformer Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), 'transformer_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, loss_fn):\n",
    "    model.eval()\n",
    "\n",
    "    losses = []\n",
    "    for lidar, non_lidar, actions in tqdm(test_loader):\n",
    "        # Move the data to the device that is used\n",
    "        lidar = lidar.to(device).unsqueeze(-1)\n",
    "        non_lidar = non_lidar.to(device).unsqueeze(-1)\n",
    "        actions = actions.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        actions_pred, _, _ = model(lidar.float(), non_lidar.float())        \n",
    "        loss = loss_fn(actions_pred, actions.float())\n",
    "        if loss.item() > 0.01:\n",
    "            print(actions_pred - actions)\n",
    "            print(loss)\n",
    "\n",
    "        # Save the loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # return the average loss for this epoch\n",
    "    return sum(losses)/len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7217, 0.1757],\n",
      "        [0.6918, 0.1718],\n",
      "        [0.6617, 0.1670],\n",
      "        [0.6315, 0.1790],\n",
      "        [0.6017, 0.1776],\n",
      "        [0.5728, 0.0842],\n",
      "        [0.5424, 0.0819],\n",
      "        [0.5121, 0.0794],\n",
      "        [0.4813, 0.0775],\n",
      "        [0.4510, 0.0751],\n",
      "        [0.4217, 0.0731],\n",
      "        [0.3888, 0.0694],\n",
      "        [0.3581, 0.0663],\n",
      "        [0.3285, 0.0643],\n",
      "        [0.2991, 0.0627],\n",
      "        [0.2696, 0.0600],\n",
      "        [0.2396, 0.0578],\n",
      "        [0.2117, 0.0570],\n",
      "        [0.1826, 0.0636],\n",
      "        [0.1522, 0.0610],\n",
      "        [0.1226, 0.0587],\n",
      "        [0.0926, 0.0581],\n",
      "        [0.0615, 0.0554],\n",
      "        [0.0325, 0.0545],\n",
      "        [0.0113, 0.0539],\n",
      "        [0.0094, 0.0416],\n",
      "        [0.0090, 0.0426],\n",
      "        [0.0085, 0.0414],\n",
      "        [0.0097, 0.0392],\n",
      "        [0.0104, 0.0366],\n",
      "        [0.0104, 0.0472],\n",
      "        [0.0091, 0.0431],\n",
      "        [0.0093, 0.0492],\n",
      "        [0.0099, 0.0483],\n",
      "        [0.0102, 0.0473],\n",
      "        [0.0091, 0.0498],\n",
      "        [0.0097, 0.0496],\n",
      "        [0.0106, 0.0490],\n",
      "        [0.0112, 0.0543],\n",
      "        [0.0130, 0.0538],\n",
      "        [0.0130, 0.0519],\n",
      "        [0.0135, 0.0516],\n",
      "        [0.0118, 0.0501],\n",
      "        [0.0113, 0.0492],\n",
      "        [0.0107, 0.0489],\n",
      "        [0.0116, 0.0489],\n",
      "        [0.0117, 0.0482],\n",
      "        [0.0105, 0.0469],\n",
      "        [0.0103, 0.0470],\n",
      "        [0.0105, 0.0455],\n",
      "        [0.0112, 0.0455],\n",
      "        [0.0108, 0.0442],\n",
      "        [0.0116, 0.0436],\n",
      "        [0.0118, 0.0447],\n",
      "        [0.0121, 0.0436],\n",
      "        [0.0114, 0.0418],\n",
      "        [0.0115, 0.0424],\n",
      "        [0.0123, 0.0439],\n",
      "        [0.0126, 0.0491],\n",
      "        [0.0133, 0.0474],\n",
      "        [0.0130, 0.0478],\n",
      "        [0.0125, 0.0481],\n",
      "        [0.0120, 0.0477],\n",
      "        [0.0122, 0.0480]], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "tensor(0.0372, grad_fn=<MseLossBackward0>)\n",
      "tensor([[ 4.0178e-02,  1.2593e-01],\n",
      "        [ 3.4020e-02,  1.0805e-01],\n",
      "        [ 3.3398e-02,  9.3616e-02],\n",
      "        [ 2.9539e-02,  2.1227e-02],\n",
      "        [ 3.3435e-02,  1.3957e-02],\n",
      "        [ 3.3684e-02,  2.0039e-02],\n",
      "        [ 3.3950e-02, -9.0780e-03],\n",
      "        [ 3.3621e-02, -3.1933e-04],\n",
      "        [ 2.5937e-02,  1.9838e-02],\n",
      "        [ 3.0998e-02,  1.9625e-02],\n",
      "        [ 2.6478e-02,  1.8281e-02],\n",
      "        [ 2.2985e-02,  1.4328e-02],\n",
      "        [ 2.9560e-02,  6.7927e-03],\n",
      "        [ 2.6515e-02, -5.0270e-02],\n",
      "        [ 2.9212e-02, -6.2882e-02],\n",
      "        [ 4.1771e-02, -4.1720e-02],\n",
      "        [ 2.8696e-02,  1.0618e-02],\n",
      "        [ 2.3389e-02,  1.6921e-02],\n",
      "        [ 2.3775e-02,  1.5888e-02],\n",
      "        [ 2.1001e-02,  1.8725e-02],\n",
      "        [ 2.7421e-02,  5.5049e-02],\n",
      "        [ 2.0270e-02, -2.1264e-02],\n",
      "        [ 2.5467e-02, -6.9384e-03],\n",
      "        [ 3.3280e-02, -1.9207e-02],\n",
      "        [ 3.2515e-02, -2.9705e-02],\n",
      "        [ 2.7449e-02, -1.6864e-02],\n",
      "        [ 2.8571e-02,  5.4451e-04],\n",
      "        [ 3.4401e-02,  5.9298e-03],\n",
      "        [ 2.4864e-02,  2.6046e-02],\n",
      "        [ 2.2256e-02,  4.2949e-02],\n",
      "        [ 2.4854e-02,  3.9886e-02],\n",
      "        [ 2.0940e-02,  3.1901e-02],\n",
      "        [ 1.9087e-02,  9.1514e-02],\n",
      "        [ 1.1289e-02,  1.3700e-01],\n",
      "        [ 6.6300e-03,  1.6455e-01],\n",
      "        [-2.9243e-03,  1.2631e-01],\n",
      "        [-5.1354e-03,  1.4822e-01],\n",
      "        [ 2.7821e-02,  2.0271e-01],\n",
      "        [ 2.1638e-02,  1.9426e-01],\n",
      "        [ 2.5710e-02,  2.0761e-01],\n",
      "        [ 1.3670e-02,  2.1709e-01],\n",
      "        [ 9.7928e-03,  2.2025e-01],\n",
      "        [-6.4193e-03,  2.2573e-01],\n",
      "        [-2.1176e-02,  1.8359e-01],\n",
      "        [-1.9720e-02,  2.0595e-01],\n",
      "        [-2.1552e-02,  2.3082e-01],\n",
      "        [-3.3006e-02,  2.4324e-01],\n",
      "        [-4.6616e-02,  1.9034e-01],\n",
      "        [-2.0044e-03,  2.5951e-01],\n",
      "        [-5.7428e-03,  3.1926e-01],\n",
      "        [-4.3684e-02,  5.0218e-01],\n",
      "        [-4.6170e-02,  3.6104e-01],\n",
      "        [-4.5022e-02,  4.8081e-01],\n",
      "        [-4.2757e-02,  4.3723e-01],\n",
      "        [-5.3356e-02,  3.3404e-01],\n",
      "        [-3.6744e-02,  2.2582e-01],\n",
      "        [-2.0968e-02,  1.7790e-01],\n",
      "        [-2.8265e-02,  2.2860e-01],\n",
      "        [-2.6502e-02,  1.6026e-01],\n",
      "        [-1.5243e-02,  3.4551e-02],\n",
      "        [-1.5872e-02,  1.9567e-01],\n",
      "        [-1.0719e-02,  3.0877e-01],\n",
      "        [-2.0226e-03,  3.7237e-01],\n",
      "        [-3.4227e-02,  4.2852e-01]], dtype=torch.float64,\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor(0.0187, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 10/28 [00:00<00:00, 97.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.6969e-02,  4.9535e-01],\n",
      "        [-4.0740e-02,  5.2424e-01],\n",
      "        [-5.3010e-02,  5.7850e-01],\n",
      "        [-4.4008e-02,  7.0381e-01],\n",
      "        [-3.7891e-02,  3.3583e-01],\n",
      "        [-3.6744e-02,  4.0470e-01],\n",
      "        [-2.5323e-02,  9.8239e-02],\n",
      "        [-3.1314e-02,  1.0084e-01],\n",
      "        [-2.6679e-02,  1.7498e-01],\n",
      "        [-1.7962e-02,  1.4961e-01],\n",
      "        [-1.9828e-02,  1.3453e-01],\n",
      "        [-1.3198e-02,  5.2264e-02],\n",
      "        [-9.7166e-03,  1.8765e-01],\n",
      "        [-1.0554e-02,  2.0946e-01],\n",
      "        [-1.5673e-02,  1.8547e-01],\n",
      "        [-1.2592e-02,  3.1354e-02],\n",
      "        [-7.7871e-03,  2.4855e-02],\n",
      "        [-4.2974e-03,  8.3902e-02],\n",
      "        [-1.8570e-03,  3.6551e-02],\n",
      "        [ 3.3350e-03,  3.7347e-02],\n",
      "        [ 9.2757e-03, -8.4831e-02],\n",
      "        [ 9.4845e-03, -1.2151e-01],\n",
      "        [ 1.3417e-02, -3.3432e-02],\n",
      "        [ 1.4975e-02, -8.4944e-02],\n",
      "        [ 9.9722e-03, -1.1124e-01],\n",
      "        [ 1.6766e-02, -1.4765e-01],\n",
      "        [ 1.6940e-02, -1.4550e-01],\n",
      "        [ 2.4251e-02, -2.2291e-01],\n",
      "        [ 2.3481e-02, -2.5179e-01],\n",
      "        [ 1.6180e-02, -1.9171e-01],\n",
      "        [ 1.7915e-02, -2.0420e-01],\n",
      "        [ 1.6747e-02, -1.7986e-01],\n",
      "        [ 1.6448e-02, -2.0800e-01],\n",
      "        [ 1.5574e-02, -2.8205e-01],\n",
      "        [-6.2258e-03, -4.1663e-01],\n",
      "        [ 2.2267e-03, -3.2109e-01],\n",
      "        [-1.3235e-02, -2.8935e-01],\n",
      "        [ 9.2221e-04, -3.9502e-01],\n",
      "        [-1.3556e-03, -3.0838e-01],\n",
      "        [ 7.8023e-03, -4.2323e-01],\n",
      "        [-1.1148e-02, -3.2589e-01],\n",
      "        [-2.5486e-02, -2.0365e-01],\n",
      "        [-9.7601e-03, -1.3294e-01],\n",
      "        [-9.7330e-03, -1.4308e-01],\n",
      "        [-2.7513e-02, -1.5003e-01],\n",
      "        [-6.6512e-02, -8.9035e-02],\n",
      "        [-7.5556e-02, -8.9939e-02],\n",
      "        [-5.5374e-02, -2.5043e-01],\n",
      "        [-7.5888e-02, -2.7117e-01],\n",
      "        [-9.5705e-02, -2.6244e-01],\n",
      "        [-6.6841e-02, -1.9989e-01],\n",
      "        [-6.2652e-02, -1.3386e-01],\n",
      "        [-3.1465e-02, -8.5120e-02],\n",
      "        [-3.6380e-02, -5.0919e-02],\n",
      "        [-3.7724e-02, -4.3360e-02],\n",
      "        [-2.9252e-02, -6.9715e-03],\n",
      "        [-1.0429e-02, -1.9604e-02],\n",
      "        [-8.0991e-03, -1.3204e-02],\n",
      "        [-1.2510e-02, -1.5739e-02],\n",
      "        [-6.0483e-03, -1.2830e-02],\n",
      "        [ 4.3963e-03, -2.2930e-02],\n",
      "        [ 2.7514e-03, -2.5099e-02],\n",
      "        [-1.4468e-03, -7.6419e-03],\n",
      "        [-6.2762e-04, -9.9289e-03]], dtype=torch.float64,\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "tensor([[ 0.0251,  0.0486],\n",
      "        [ 0.0253,  0.0446],\n",
      "        [ 0.0254,  0.0451],\n",
      "        [ 0.0253,  0.0393],\n",
      "        [ 0.0250,  0.0371],\n",
      "        [ 0.0254,  0.0416],\n",
      "        [ 0.0252,  0.0437],\n",
      "        [ 0.0254,  0.0468],\n",
      "        [ 0.0255,  0.0479],\n",
      "        [ 0.0267,  0.0537],\n",
      "        [ 0.0268,  0.0605],\n",
      "        [ 0.0268,  0.0632],\n",
      "        [ 0.0268,  0.0730],\n",
      "        [ 0.0268,  0.0679],\n",
      "        [ 0.0271,  0.0810],\n",
      "        [ 0.0267,  0.0786],\n",
      "        [ 0.0266,  0.1152],\n",
      "        [ 0.0266,  0.1131],\n",
      "        [ 0.0265,  0.1084],\n",
      "        [ 0.0264,  0.1069],\n",
      "        [ 0.0255,  0.1047],\n",
      "        [ 0.0256,  0.0799],\n",
      "        [ 0.3757,  0.4587],\n",
      "        [ 0.3456,  0.4436],\n",
      "        [ 0.3141,  0.4082],\n",
      "        [ 0.2858,  0.3839],\n",
      "        [ 0.2610,  0.3521],\n",
      "        [ 0.2298,  0.3348],\n",
      "        [ 0.1984,  0.3159],\n",
      "        [ 0.1736,  0.2544],\n",
      "        [ 0.1469,  0.2953],\n",
      "        [ 0.1173,  0.2630],\n",
      "        [ 0.0979,  0.2259],\n",
      "        [ 0.0678,  0.1979],\n",
      "        [ 0.0417,  0.1704],\n",
      "        [ 0.0129,  0.1464],\n",
      "        [-0.0145,  0.1068],\n",
      "        [-0.0466,  0.0539],\n",
      "        [-0.0674,  0.0308],\n",
      "        [-0.0711,  0.0324],\n",
      "        [-0.0688,  0.0917],\n",
      "        [-0.0674,  0.0932],\n",
      "        [-0.0552,  0.0582],\n",
      "        [-0.0505,  0.0489],\n",
      "        [-0.0456,  0.0481],\n",
      "        [-0.0428,  0.1518],\n",
      "        [-0.0424,  0.1352],\n",
      "        [-0.0253,  0.1097],\n",
      "        [-0.0198,  0.0985],\n",
      "        [-0.0161,  0.0765],\n",
      "        [-0.0142,  0.1085],\n",
      "        [-0.0089,  0.0948],\n",
      "        [-0.0053,  0.1196],\n",
      "        [-0.0022,  0.1034],\n",
      "        [ 0.0065,  0.0753],\n",
      "        [ 0.0051,  0.1764],\n",
      "        [ 0.0061,  0.1584],\n",
      "        [ 0.0185,  0.0963],\n",
      "        [ 0.0172,  0.0835],\n",
      "        [ 0.0202,  0.0596],\n",
      "        [ 0.0239,  0.0694],\n",
      "        [ 0.0247,  0.0574],\n",
      "        [ 0.0239,  0.0776],\n",
      "        [ 0.0256,  0.0651]], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "tensor([[ 0.0098,  0.1495],\n",
      "        [ 0.0033,  0.1780],\n",
      "        [ 0.0210,  0.2141],\n",
      "        [ 0.0299,  0.1980],\n",
      "        [ 0.0174,  0.2001],\n",
      "        [ 0.0240,  0.2307],\n",
      "        [ 0.0111,  0.2540],\n",
      "        [ 0.0094,  0.1970],\n",
      "        [ 0.0076,  0.3054],\n",
      "        [-0.0051,  0.3229],\n",
      "        [-0.0160,  0.2364],\n",
      "        [-0.0226,  0.2314],\n",
      "        [-0.0286,  0.2957],\n",
      "        [-0.0295,  0.2916],\n",
      "        [-0.0075,  0.3122],\n",
      "        [-0.0115,  0.3976],\n",
      "        [ 0.0040,  0.3652],\n",
      "        [-0.0030,  0.2944],\n",
      "        [-0.0137,  0.2542],\n",
      "        [-0.0155,  0.2359],\n",
      "        [-0.0189,  0.2241],\n",
      "        [-0.0127,  0.2567],\n",
      "        [-0.0154,  0.1586],\n",
      "        [ 0.0081,  0.0516],\n",
      "        [ 0.0056,  0.1161],\n",
      "        [ 0.0055,  0.0767],\n",
      "        [-0.0239,  0.0955],\n",
      "        [-0.0233,  0.1772],\n",
      "        [-0.0059,  0.1457],\n",
      "        [-0.0084,  0.1601],\n",
      "        [-0.0097,  0.1688],\n",
      "        [-0.0097,  0.1292],\n",
      "        [-0.0131,  0.1115],\n",
      "        [-0.0146,  0.3658],\n",
      "        [-0.0122,  0.3384],\n",
      "        [-0.0241,  0.4705],\n",
      "        [-0.0168,  0.5739],\n",
      "        [-0.0138,  0.1121],\n",
      "        [-0.0224,  0.1298],\n",
      "        [-0.0166,  0.1151],\n",
      "        [-0.0221,  0.1345],\n",
      "        [-0.0267,  0.1365],\n",
      "        [-0.0080,  0.0327],\n",
      "        [-0.0013,  0.0464],\n",
      "        [ 0.0029,  0.0906],\n",
      "        [ 0.0067,  0.0761],\n",
      "        [ 0.0075,  0.0755],\n",
      "        [ 0.0061, -0.1214],\n",
      "        [ 0.0092, -0.1318],\n",
      "        [ 0.0088, -0.1318],\n",
      "        [ 0.0134, -0.0717],\n",
      "        [ 0.0195, -0.0023],\n",
      "        [ 0.0263, -0.0230],\n",
      "        [ 0.0283, -0.0660],\n",
      "        [ 0.0273, -0.0211],\n",
      "        [ 0.0271, -0.0511],\n",
      "        [ 0.0264, -0.0291],\n",
      "        [ 0.0255, -0.0422],\n",
      "        [ 0.0254, -0.0904],\n",
      "        [ 0.0239, -0.0891],\n",
      "        [ 0.0143, -0.0993],\n",
      "        [ 0.0202, -0.0621],\n",
      "        [ 0.0234, -0.0571],\n",
      "        [ 0.0216, -0.1141]], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.0213, 0.0738],\n",
      "        [0.0218, 0.0656],\n",
      "        [0.0213, 0.0781],\n",
      "        [0.0215, 0.0770],\n",
      "        [0.0213, 0.0681],\n",
      "        [0.0214, 0.0724],\n",
      "        [0.0234, 0.0718],\n",
      "        [0.0234, 0.0783],\n",
      "        [0.0234, 0.0793],\n",
      "        [0.0239, 0.0524],\n",
      "        [0.0241, 0.0542],\n",
      "        [0.0253, 0.0560],\n",
      "        [0.0253, 0.0623],\n",
      "        [0.0252, 0.0694],\n",
      "        [0.0242, 0.0732],\n",
      "        [0.0215, 0.0726],\n",
      "        [0.0217, 0.0720],\n",
      "        [0.0210, 0.0638],\n",
      "        [0.0210, 0.0591],\n",
      "        [0.0213, 0.0562],\n",
      "        [0.0228, 0.0579],\n",
      "        [0.0238, 0.0576],\n",
      "        [0.0238, 0.0593],\n",
      "        [0.0239, 0.0563],\n",
      "        [0.0222, 0.0516],\n",
      "        [0.0219, 0.0614],\n",
      "        [0.0222, 0.0605],\n",
      "        [0.0221, 0.0719],\n",
      "        [0.0223, 0.0661],\n",
      "        [0.0223, 0.0866],\n",
      "        [0.0224, 0.0823],\n",
      "        [0.0222, 0.0977],\n",
      "        [0.0226, 0.0900],\n",
      "        [0.0249, 0.0870],\n",
      "        [0.0250, 0.0841],\n",
      "        [0.0245, 0.0842],\n",
      "        [0.0238, 0.0850],\n",
      "        [0.0236, 0.0792],\n",
      "        [0.0234, 0.0781],\n",
      "        [0.0229, 0.0728],\n",
      "        [0.0227, 0.0712],\n",
      "        [0.6474, 0.2081],\n",
      "        [0.6176, 0.2008],\n",
      "        [0.5879, 0.1930],\n",
      "        [0.5581, 0.1853],\n",
      "        [0.5277, 0.1768],\n",
      "        [0.4982, 0.1715],\n",
      "        [0.4687, 0.1625],\n",
      "        [0.4397, 0.1528],\n",
      "        [0.4098, 0.1428],\n",
      "        [0.3803, 0.1372],\n",
      "        [0.3503, 0.1336],\n",
      "        [0.3203, 0.1234],\n",
      "        [0.2902, 0.1169],\n",
      "        [0.2574, 0.1050],\n",
      "        [0.2291, 0.0986],\n",
      "        [0.2013, 0.0962],\n",
      "        [0.1721, 0.0910],\n",
      "        [0.1424, 0.0836],\n",
      "        [0.1128, 0.0852],\n",
      "        [0.0817, 0.0781],\n",
      "        [0.0518, 0.0690],\n",
      "        [0.0302, 0.0650],\n",
      "        [0.0292, 0.0687]], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "tensor(0.0305, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 21/28 [00:00<00:00, 103.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.1413e-02,  1.4456e-02],\n",
      "        [ 3.1290e-02,  9.3534e-03],\n",
      "        [ 3.0749e-02,  3.8231e-02],\n",
      "        [ 2.9482e-02,  5.3162e-02],\n",
      "        [ 1.8824e-02,  5.9932e-02],\n",
      "        [ 2.5105e-02,  6.4435e-02],\n",
      "        [ 2.2251e-02,  9.6680e-02],\n",
      "        [ 1.2756e-02,  1.4278e-01],\n",
      "        [ 1.1439e-02,  1.9481e-01],\n",
      "        [ 1.2282e-02,  2.1942e-01],\n",
      "        [-3.3336e-04,  2.2054e-01],\n",
      "        [-7.9889e-03,  1.9824e-01],\n",
      "        [ 2.7872e-02,  2.9851e-01],\n",
      "        [ 1.9977e-02,  2.4661e-01],\n",
      "        [ 2.6614e-02,  2.8574e-01],\n",
      "        [ 1.0597e-02,  2.7081e-01],\n",
      "        [-6.0883e-03,  2.4660e-01],\n",
      "        [-1.8414e-02,  2.5874e-01],\n",
      "        [-1.9450e-02,  2.6889e-01],\n",
      "        [-2.3200e-02,  2.6673e-01],\n",
      "        [-2.2098e-02,  2.4218e-01],\n",
      "        [-3.1376e-02,  2.5061e-01],\n",
      "        [-2.5258e-02,  1.8139e-01],\n",
      "        [-4.8453e-02,  3.5137e-01],\n",
      "        [-3.4802e-02,  3.5921e-01],\n",
      "        [-4.4136e-02,  5.1723e-01],\n",
      "        [-3.7229e-02,  4.1608e-01],\n",
      "        [-4.6981e-02,  4.9984e-01],\n",
      "        [-4.8163e-02,  4.6484e-01],\n",
      "        [-5.4168e-02,  4.3061e-01],\n",
      "        [-5.3179e-02,  2.5141e-01],\n",
      "        [-2.3555e-02,  3.2967e-01],\n",
      "        [-3.5458e-02,  3.5735e-01],\n",
      "        [-2.5053e-02,  3.7137e-01],\n",
      "        [-2.7399e-02,  2.9916e-01],\n",
      "        [-1.5725e-02,  2.6608e-01],\n",
      "        [-2.0473e-02,  2.7868e-01],\n",
      "        [-4.9179e-02,  4.6843e-01],\n",
      "        [-4.3492e-02,  2.9670e-01],\n",
      "        [-4.5553e-02,  5.3986e-01],\n",
      "        [-4.3917e-02,  5.2784e-01],\n",
      "        [-4.1994e-02,  6.4151e-01],\n",
      "        [-4.2835e-02,  7.3650e-01],\n",
      "        [-4.0684e-02,  3.4359e-01],\n",
      "        [-3.7104e-02,  4.3114e-01],\n",
      "        [-3.9131e-02,  1.9280e-01],\n",
      "        [-4.1708e-02,  1.5979e-01],\n",
      "        [-4.2351e-02,  1.4392e-01],\n",
      "        [-3.1331e-02, -3.4240e-02],\n",
      "        [-2.8408e-02, -1.8769e-02],\n",
      "        [-2.7136e-02, -1.9555e-03],\n",
      "        [-2.9338e-02, -7.2145e-02],\n",
      "        [-2.2531e-02, -6.3029e-02],\n",
      "        [-1.5315e-02, -3.7732e-02],\n",
      "        [-1.6375e-02, -4.5844e-02],\n",
      "        [-1.6892e-02, -5.6736e-02],\n",
      "        [-1.3658e-02, -1.0658e-01],\n",
      "        [-1.7752e-02, -1.3000e-01],\n",
      "        [-4.3550e-03, -7.2538e-02],\n",
      "        [ 7.1186e-03, -8.7968e-02],\n",
      "        [ 8.1433e-03, -1.2042e-01],\n",
      "        [ 1.2235e-02, -1.0080e-01],\n",
      "        [ 1.2638e-02, -1.1857e-01],\n",
      "        [ 1.0225e-02, -1.5620e-01]], dtype=torch.float64,\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor(0.0419, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:00<00:00, 102.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final val loss: 0.009292492597264104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(config_dict)\n",
    "model.load_state_dict(torch.load('transformer_model.pth', map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "device = 'cpu'\n",
    "\n",
    "# take world idx 0 as example\n",
    "dataset = KULBarnDataset(df[df['world_idx'] == 0], \"val\")\n",
    "print(len(dataset))\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "final_val_loss = test_model(model, loader, loss_fn)\n",
    "print(\"Final val loss:\", final_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hydra'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[126], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhydra\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01momegaconf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OmegaConf\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'hydra'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import hydra\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "import pathlib\n",
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "import numpy as np\n",
    "import random\n",
    "import wandb\n",
    "import tqdm\n",
    "import shutil\n",
    "from diffusion_policy.policy.diffusion_unet_lowdim_policy import DiffusionUnetLowdimPolicy\n",
    "from diffusion_policy.workspace.train_diffusion_unet_lowdim_workspace import TrainDiffusionUnetLowdimWorkspace\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion_policy.dataset.base_dataset import BaseLowdimDataset\n",
    "from typing import Dict\n",
    "import torch\n",
    "import numpy as np\n",
    "import copy\n",
    "from diffusion_policy.common.pytorch_util import dict_apply\n",
    "from diffusion_policy.common.replay_buffer import ReplayBuffer\n",
    "from diffusion_policy.common.sampler import (\n",
    "    SequenceSampler, get_val_mask, downsample_mask)\n",
    "from diffusion_policy.model.common.normalizer import LinearNormalizer\n",
    "from diffusion_policy.dataset.base_dataset import BaseLowdimDataset\n",
    "\n",
    "\n",
    "class KULBarnDiffusionDataset(BaseLowdimDataset):\n",
    "    def __init__(self, df, horizon=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.data = df\n",
    "        self.get_local_goal()\n",
    "\n",
    "        self.data = self.data.drop(columns=[\n",
    "            'timestep', 'actual_time', 'optimal_time', \n",
    "            'pos_x', 'pos_y', 'pose_heading', 'goal_x', 'goal_y', 'success'\n",
    "        ])\n",
    "        \n",
    "        self.data = pd.DataFrame(self.data, columns=self.data.columns)\n",
    "        self.horizon = horizon\n",
    "\n",
    "        # Process data columns\n",
    "        self.lidar_cols = [col for col in self.data.columns if 'lidar' in col]\n",
    "        self.actions_cols = [col for col in self.data.columns if 'cmd' in col]\n",
    "        self.non_lidar_cols = [col for col in self.data.columns if col not in self.lidar_cols and col not in self.actions_cols and col != 'world_idx']\n",
    "\n",
    "        self.lidar_data = self.data[self.lidar_cols].values\n",
    "        self.non_lidar_data = self.data[self.non_lidar_cols].values\n",
    "        self.actions_data = self.data[self.actions_cols].values\n",
    "\n",
    "        print(\"Lidar Columns:\", self.lidar_cols)\n",
    "        print(\"Non Lidar Columns:\", self.non_lidar_cols)\n",
    "        print(\"Action Columns:\", self.actions_cols)     \n",
    "\n",
    "        self.grouped_data = self.data.groupby(self.data['world_idx'])\n",
    "        self.horizon = horizon\n",
    "        path_lengths = [len(group) for name, group in self.grouped_data]\n",
    "        self.indices = self.make_indices(path_lengths, horizon)\n",
    "\n",
    "    def get_local_goal(self):\n",
    "        x = self.data['pos_x']\n",
    "        y = self.data['pos_y']\n",
    "        theta = self.data['pose_heading']\n",
    "        goal_x = self.data['goal_x']\n",
    "        goal_y = self.data['goal_y']\n",
    "        self.data['local_x'] = (goal_x - x) * np.cos(theta) + (goal_y - y) * np.sin(theta)\n",
    "        self.data['local_y'] = -(goal_x - x) * np.sin(theta) + (goal_y - y) * np.cos(theta)\n",
    "\n",
    "    def make_indices(self, path_lengths, horizon):\n",
    "        indices = []\n",
    "        for i, path_length in enumerate(path_lengths):\n",
    "            max_start = path_length - horizon\n",
    "            for start in range(max_start):\n",
    "                end = start + horizon\n",
    "                indices.append((i, start, end))\n",
    "        indices = np.array(indices)\n",
    "        return indices\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
    "        idx = self.indices[idx]\n",
    "        start = idx[1]\n",
    "        end = idx[2]\n",
    "\n",
    "        data = {\n",
    "            'obs': self.lidar_data[start:end],\n",
    "            'cond': self.non_lidar_data[start:end],\n",
    "            'action': self.actions_data[start:end],\n",
    "        }\n",
    "        torch_data = dict_apply(data, torch.from_numpy)\n",
    "        return torch_data\n",
    "\n",
    "    def get_normalizer(self, mode='limits', **kwargs):\n",
    "        normalizer = LinearNormalizer()\n",
    "        # train it in using self.data as a dictionary\n",
    "        data_dict = {\n",
    "            'obs': self.lidar_data,\n",
    "            'cond': self.non_lidar_data,\n",
    "            'action': self.actions_data\n",
    "        }\n",
    "        normalizer.fit(data=data_dict, mode=mode, **kwargs)\n",
    "        return normalizer\n",
    "\n",
    "    def get_all_actions(self) -> torch.Tensor:\n",
    "        return torch.from_numpy(self.actions_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = KULBarnDiffusionDataset(train_df)\n",
    "train_dataloader = DataLoader(train_dataset)\n",
    "normalizer = train_dataset.get_normalizer()\n",
    "print(len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_dataloader:\n",
    "    # print(batch)\n",
    "    print(batch['obs'].shape)\n",
    "    print(batch['cond'].shape)\n",
    "    print(batch['action'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion_policy.policy.diffusion_unet_lidar_policy import DiffusionUnetLidarPolicy\n",
    "from diffusion_policy.model.diffusion.conditional_unet1d import ConditionalUnet1D\n",
    "from diffusers.schedulers.scheduling_ddpm import DDPMScheduler\n",
    "\n",
    "obs_dim = batch['obs'].shape[-1]\n",
    "action_dim = batch['action'].shape[-1]\n",
    "input_dim = obs_dim + action_dim\n",
    "model = ConditionalUnet1D(input_dim=input_dim)\n",
    "noise_scheduler = DDPMScheduler(num_train_timesteps=1000, beta_schedule='linear')\n",
    "horizon = 4\n",
    "policy = DiffusionUnetLidarPolicy(\n",
    "    model=model, \n",
    "    noise_scheduler=noise_scheduler, \n",
    "    horizon=horizon, \n",
    "    obs_dim=obs_dim, \n",
    "    action_dim=action_dim, \n",
    "    n_obs_steps=4,\n",
    "    n_action_steps=4,\n",
    "    pred_action_steps_only=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy.set_normalizer(normalizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "losses = []\n",
    "save_loss_every = 1000\n",
    "total_loss = 0\n",
    "count = 0\n",
    "\n",
    "optimizer = optim.Adam(policy.model.parameters(), lr=5e-5)\n",
    "policy.model.train()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        loss = policy.compute_loss(batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        count += 1\n",
    "        if count >= save_loss_every:\n",
    "            curr_loss = total_loss / save_loss_every\n",
    "            print(\"Loss:\", curr_loss)\n",
    "            losses.append(curr_loss)\n",
    "            total_loss = 0\n",
    "            count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robodiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
