{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>success</th>\n",
       "      <th>actual_time</th>\n",
       "      <th>optimal_time</th>\n",
       "      <th>world_idx</th>\n",
       "      <th>timestep</th>\n",
       "      <th>goal_x</th>\n",
       "      <th>goal_y</th>\n",
       "      <th>lidar_0</th>\n",
       "      <th>lidar_1</th>\n",
       "      <th>lidar_2</th>\n",
       "      <th>...</th>\n",
       "      <th>lidar_359</th>\n",
       "      <th>pos_x</th>\n",
       "      <th>pos_y</th>\n",
       "      <th>pose_heading</th>\n",
       "      <th>twist_linear</th>\n",
       "      <th>twist_angular</th>\n",
       "      <th>cmd_vel_linear</th>\n",
       "      <th>cmd_vel_angular</th>\n",
       "      <th>local_goal_x</th>\n",
       "      <th>local_goal_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>11.53</td>\n",
       "      <td>6.776516</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.953487</td>\n",
       "      <td>2.869737</td>\n",
       "      <td>2.848471</td>\n",
       "      <td>...</td>\n",
       "      <td>3.010891</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>1.547277</td>\n",
       "      <td>0.015216</td>\n",
       "      <td>0.004864</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.013916</td>\n",
       "      <td>0.997539</td>\n",
       "      <td>0.073423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>11.53</td>\n",
       "      <td>6.776516</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.956702</td>\n",
       "      <td>2.871896</td>\n",
       "      <td>2.849361</td>\n",
       "      <td>...</td>\n",
       "      <td>3.011203</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>0.002372</td>\n",
       "      <td>1.547351</td>\n",
       "      <td>0.038166</td>\n",
       "      <td>0.012513</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.018555</td>\n",
       "      <td>1.021175</td>\n",
       "      <td>0.073934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>11.53</td>\n",
       "      <td>6.776516</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.958278</td>\n",
       "      <td>2.869057</td>\n",
       "      <td>2.851222</td>\n",
       "      <td>...</td>\n",
       "      <td>3.013201</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.004364</td>\n",
       "      <td>1.547393</td>\n",
       "      <td>0.065010</td>\n",
       "      <td>0.006605</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.023194</td>\n",
       "      <td>1.019185</td>\n",
       "      <td>0.073891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>11.53</td>\n",
       "      <td>6.776516</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.960670</td>\n",
       "      <td>2.870363</td>\n",
       "      <td>2.851820</td>\n",
       "      <td>...</td>\n",
       "      <td>3.010752</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.006967</td>\n",
       "      <td>1.547525</td>\n",
       "      <td>0.093685</td>\n",
       "      <td>0.022431</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.011172</td>\n",
       "      <td>1.016592</td>\n",
       "      <td>0.073756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>11.53</td>\n",
       "      <td>6.776516</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.962370</td>\n",
       "      <td>2.871268</td>\n",
       "      <td>2.855664</td>\n",
       "      <td>...</td>\n",
       "      <td>3.011739</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.010177</td>\n",
       "      <td>1.547590</td>\n",
       "      <td>0.123362</td>\n",
       "      <td>0.008801</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.013033</td>\n",
       "      <td>1.013386</td>\n",
       "      <td>0.073689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 376 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   success  actual_time  optimal_time  world_idx  timestep  goal_x  goal_y  \\\n",
       "0     True        11.53      6.776516          0         0     0.0    10.0   \n",
       "1     True        11.53      6.776516          0         1     0.0    10.0   \n",
       "2     True        11.53      6.776516          0         2     0.0    10.0   \n",
       "3     True        11.53      6.776516          0         3     0.0    10.0   \n",
       "4     True        11.53      6.776516          0         4     0.0    10.0   \n",
       "\n",
       "    lidar_0   lidar_1   lidar_2  ...  lidar_359     pos_x     pos_y  \\\n",
       "0  2.953487  2.869737  2.848471  ...   3.010891 -0.000056  0.001010   \n",
       "1  2.956702  2.871896  2.849361  ...   3.011203 -0.000025  0.002372   \n",
       "2  2.958278  2.869057  2.851222  ...   3.013201  0.000020  0.004364   \n",
       "3  2.960670  2.870363  2.851820  ...   3.010752  0.000080  0.006967   \n",
       "4  2.962370  2.871268  2.855664  ...   3.011739  0.000154  0.010177   \n",
       "\n",
       "   pose_heading  twist_linear  twist_angular  cmd_vel_linear  cmd_vel_angular  \\\n",
       "0      1.547277      0.015216       0.004864            0.09         0.013916   \n",
       "1      1.547351      0.038166       0.012513            0.12         0.018555   \n",
       "2      1.547393      0.065010       0.006605            0.15         0.023194   \n",
       "3      1.547525      0.093685       0.022431            0.18         0.011172   \n",
       "4      1.547590      0.123362       0.008801            0.21         0.013033   \n",
       "\n",
       "   local_goal_x  local_goal_y  \n",
       "0      0.997539      0.073423  \n",
       "1      1.021175      0.073934  \n",
       "2      1.019185      0.073891  \n",
       "3      1.016592      0.073756  \n",
       "4      1.013386      0.073689  \n",
       "\n",
       "[5 rows x 376 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('../inspection_data/data_50Hz.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove rows with success = 0\n",
    "df = df[df['success'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch Dataset\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class KULBarnDataset(Dataset):\n",
    "    def get_normalized_goal(self):\n",
    "        x = self.data['pos_x']\n",
    "        y = self.data['pos_y']\n",
    "        goal_x = self.data['goal_x']\n",
    "        goal_y = self.data['goal_y']\n",
    "        theta = self.data['pose_heading']\n",
    "        self.data['goal_x'] = np.cos(theta) * (goal_x - x) + np.sin(theta) * (goal_y - y)\n",
    "        self.data['goal_y'] = -np.sin(theta) * (goal_x - x) + np.cos(theta) * (goal_y - y)\n",
    "\n",
    "    def __init__(self, df, mode=\"train\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.data = df\n",
    "        self.get_normalized_goal()  \n",
    "        \n",
    "        # get all the column values that contain the word lidar\n",
    "        self.lidar_cols = [\"lidar_\" + str(i) for i in range(0, 360, 1)]\n",
    "        # get actions columns\n",
    "        self.actions_cols = ['cmd_vel_linear', 'cmd_vel_angular']\n",
    "        # get other columns\n",
    "        self.non_lidar_cols = ['local_goal_x', 'local_goal_y', 'goal_x', 'goal_y']\n",
    "\n",
    "        # if mode == \"train\":\n",
    "        #     # Manually compute the min and max values for each column\n",
    "        #     self.min = self.data.min()\n",
    "        #     self.max = self.data.max()\n",
    "        #     # Save the mean and std to a JSON file\n",
    "        #     scaler_params = {\n",
    "        #         'min': self.min.to_dict(),\n",
    "        #         'max': self.max.to_dict()\n",
    "        #     }\n",
    "        #     with open('scaler_params.json', 'w') as f:\n",
    "        #         json.dump(scaler_params, f)\n",
    "        # else:\n",
    "        #     # Load the mean and std from the JSON file\n",
    "        #     with open('scaler_params.json', 'r') as f:\n",
    "        #         scaler_params = json.load(f)\n",
    "        #     self.min = pd.Series(scaler_params['min'])\n",
    "        #     self.max = pd.Series(scaler_params['max'])\n",
    "        \n",
    "        # dont normalizer local_x and local_y\n",
    "        # self.normalized_data = (self.data - self.min) / (self.max - self.min)\n",
    "        self.normalized_data = self.data\n",
    "         \n",
    "        self.lidar_data = self.normalized_data[self.lidar_cols].values\n",
    "        self.non_lidar_data = self.normalized_data[self.non_lidar_cols].values\n",
    "        self.actions_data = self.normalized_data[self.actions_cols].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        lidar = self.lidar_data[idx]\n",
    "        non_lidar = self.non_lidar_data[idx]\n",
    "        actions = self.actions_data[idx]\n",
    "        return lidar, non_lidar, actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take random 90% of the world ids for training\n",
    "ids = df['world_idx'].unique()\n",
    "\n",
    "test_ids = list(range(0, 300, 5))\n",
    "\n",
    "non_test_ids = np.setdiff1d(ids, test_ids)\n",
    "\n",
    "train_ids = np.random.choice(non_test_ids, int(0.8 * len(non_test_ids)), replace=False)\n",
    "train_df = df[df['world_idx'].isin(train_ids)]\n",
    "train_dataset = KULBarnDataset(train_df, mode=\"train\")\n",
    "\n",
    "# take the remaining of the world ids for validation\n",
    "val_ids = np.setdiff1d(non_test_ids, train_ids)\n",
    "val_df = df[df['world_idx'].isin(val_ids)]\n",
    "val_dataset = KULBarnDataset(val_df, mode=\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192 48\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ids), len(val_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Length: 356623\n",
      "Val Dataset Length: 86379\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Dataset Length:\", len(train_dataset))\n",
    "print(\"Val Dataset Length:\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non lidar shape: torch.Size([64, 4])\n",
      "Lidar shape: torch.Size([64, 360])\n",
      "Train loader size: 5573\n",
      "Val loader size: 1350\n",
      "tensor([[1.2042, 1.2010, 1.2006,  ..., 0.7230, 0.7289, 0.7393],\n",
      "        [5.0000, 5.0000, 5.0000,  ..., 1.8720, 1.8806, 1.8984],\n",
      "        [4.3470, 4.5073, 4.7787,  ..., 0.6869, 0.7010, 0.8091],\n",
      "        ...,\n",
      "        [5.0000, 5.0000, 5.0000,  ..., 5.0000, 5.0000, 5.0000],\n",
      "        [1.0508, 1.0547, 1.0599,  ..., 5.0000, 5.0000, 5.0000],\n",
      "        [0.6421, 0.6455, 0.6493,  ..., 0.9102, 0.9169, 0.9384]],\n",
      "       dtype=torch.float64) tensor([[ 1.0088e+00, -3.5703e-02,  5.9112e+00, -5.7129e-01],\n",
      "        [ 9.8328e-01,  2.6551e-01,  3.7076e+00,  6.4741e+00],\n",
      "        [ 9.6028e-01,  2.8164e-01,  3.5545e+00,  4.2327e+00],\n",
      "        [ 9.8061e-01,  2.1264e-01,  5.1315e+00, -5.5955e+00],\n",
      "        [ 1.0209e+00,  3.8610e-02,  5.1080e+00, -4.9602e-01],\n",
      "        [ 1.0104e+00,  2.7528e-02,  6.7788e+00, -2.6475e-01],\n",
      "        [ 1.0004e+00, -5.7744e-02,  1.4542e+00, -1.6251e-01],\n",
      "        [ 1.0119e+00, -2.5100e-02,  3.0506e+00, -2.9924e-01],\n",
      "        [ 1.0069e+00, -1.2296e-01,  3.9403e+00, -1.7460e+00],\n",
      "        [ 1.0090e+00, -3.6122e-02,  7.7484e+00,  1.3032e-01],\n",
      "        [ 1.0080e+00, -1.3317e-02,  7.5919e+00, -4.8836e-01],\n",
      "        [ 1.0002e+00, -1.4965e-02,  8.9064e+00, -5.4051e-01],\n",
      "        [ 9.9914e-01,  5.2376e-02,  3.4837e+00,  4.0771e-01],\n",
      "        [ 1.0133e+00,  5.2077e-02,  6.4892e+00, -3.1805e+00],\n",
      "        [ 9.9290e-01, -1.7476e-01,  9.1501e+00, -2.2815e+00],\n",
      "        [ 1.0221e+00, -3.7916e-02,  6.0536e+00,  2.6381e+00],\n",
      "        [ 1.0132e+00,  2.1554e-02,  4.8650e+00, -5.9620e+00],\n",
      "        [ 1.0208e+00, -3.2034e-02,  2.1569e+00, -2.0510e-01],\n",
      "        [ 9.8783e-01, -2.3095e-01,  9.3185e+00, -2.5543e+00],\n",
      "        [ 1.0163e+00,  2.6597e-02,  3.0641e+00,  2.7689e-01],\n",
      "        [ 1.0194e+00, -1.8569e-02,  3.5326e+00, -3.1030e-01],\n",
      "        [ 9.2812e-01,  4.0370e-01,  7.2079e+00,  2.7026e+00],\n",
      "        [ 5.8466e-01,  8.2894e-01,  9.0175e+00,  1.8493e+00],\n",
      "        [ 1.0051e+00, -8.1195e-02,  9.8367e+00, -1.1837e+00],\n",
      "        [ 9.6387e-01, -2.6652e-01,  9.3919e+00,  4.0829e-01],\n",
      "        [ 1.0221e+00, -4.9108e-02,  1.3494e+00, -1.3721e-01],\n",
      "        [ 1.0143e+00, -4.1944e-02,  4.1394e+00, -1.8567e+00],\n",
      "        [ 8.4511e-01,  5.5641e-01,  3.5923e+00,  4.4006e+00],\n",
      "        [ 9.7460e-01, -3.1570e-01,  9.0821e+00, -3.3254e+00],\n",
      "        [ 1.0116e+00, -9.8198e-02,  9.4192e+00, -1.0825e+00],\n",
      "        [ 1.0092e+00, -5.9584e-02,  9.4674e+00, -5.9486e-01],\n",
      "        [ 1.0042e+00, -6.0068e-02,  3.5974e+00, -5.4265e-01],\n",
      "        [ 1.0087e+00,  2.3718e-02,  5.5580e+00,  5.1233e-01],\n",
      "        [ 1.0123e+00, -5.2790e-02,  7.8857e+00,  1.9171e+00],\n",
      "        [ 1.0190e+00, -6.4401e-02,  1.0429e+00, -7.3801e-02],\n",
      "        [ 1.0001e+00, -7.9665e-02,  6.7466e+00, -1.8980e+00],\n",
      "        [ 1.0006e+00, -7.2730e-02,  5.6946e+00,  5.1969e-01],\n",
      "        [ 1.0172e+00, -1.6333e-02,  7.6857e+00,  3.2575e-01],\n",
      "        [ 1.0231e+00, -5.5299e-02,  1.6526e+00, -1.6465e-01],\n",
      "        [ 1.0127e+00, -1.6862e-02,  2.7302e+00, -2.3087e-01],\n",
      "        [ 1.0081e+00, -4.3628e-02,  8.9231e+00, -1.0227e+00],\n",
      "        [ 1.0132e+00, -9.3155e-02,  6.7536e+00, -6.1629e-02],\n",
      "        [ 1.0033e+00,  2.3447e-02,  4.1229e+00, -2.2909e-01],\n",
      "        [ 1.0080e+00, -1.3892e-02,  3.0989e+00, -2.6336e-01],\n",
      "        [ 1.0109e+00, -1.9094e-02,  2.3763e+00, -2.3509e-01],\n",
      "        [ 8.7819e-01,  4.9778e-01,  4.5018e+00,  5.4920e+00],\n",
      "        [ 9.9255e-01, -1.6281e-01,  7.8612e+00,  4.1572e+00],\n",
      "        [ 1.0083e+00, -7.1334e-02,  7.6016e+00,  9.7430e-01],\n",
      "        [ 1.0005e+00, -5.3560e-02,  2.5890e+00, -3.2699e-01],\n",
      "        [ 1.0025e+00,  3.5403e-02,  9.4024e+00,  7.8580e-02],\n",
      "        [ 1.0153e+00, -1.1709e-01,  6.5032e+00, -1.4717e+00],\n",
      "        [ 9.9944e-01, -5.0965e-02,  6.6611e+00,  2.6347e+00],\n",
      "        [ 1.0032e+00, -3.5798e-02,  7.1484e+00, -8.6201e-01],\n",
      "        [ 1.0163e+00,  1.4144e-02,  1.6143e+00,  8.8878e-02],\n",
      "        [ 1.0027e+00,  1.2442e-02,  8.0081e+00, -8.9576e-01],\n",
      "        [ 9.9749e-01, -1.9110e-01,  8.9519e+00, -3.0526e+00],\n",
      "        [ 1.0121e+00,  6.6298e-02,  6.4713e+00,  1.9428e+00],\n",
      "        [ 1.0068e+00,  8.0103e-02,  7.5167e+00,  3.0626e+00],\n",
      "        [ 1.0173e+00, -3.3992e-02,  1.9945e+00,  1.0919e-02],\n",
      "        [ 1.0042e+00,  7.3841e-03,  8.4547e+00, -1.0662e+00],\n",
      "        [ 1.0158e+00, -2.1503e-02,  3.9775e+00, -3.4620e-01],\n",
      "        [ 1.0102e+00, -5.6275e-02,  2.1071e+00, -2.4635e-01],\n",
      "        [ 1.0102e+00, -1.1673e-01,  6.4456e+00, -4.2077e+00],\n",
      "        [ 9.9876e-01,  1.1287e-01,  7.1998e+00,  6.0675e-01]],\n",
      "       dtype=torch.float64) tensor([[ 0.8000, -0.0439],\n",
      "        [ 0.8000,  0.0693],\n",
      "        [ 0.8000,  0.1975],\n",
      "        [ 0.8000,  0.5774],\n",
      "        [ 0.8000,  0.0427],\n",
      "        [ 0.8000,  0.0486],\n",
      "        [ 0.8000, -0.1114],\n",
      "        [ 0.8000, -0.0254],\n",
      "        [ 0.8000, -0.1851],\n",
      "        [ 0.8000, -0.0370],\n",
      "        [ 0.8000, -0.0192],\n",
      "        [ 0.8000, -0.0275],\n",
      "        [ 0.8000,  0.0937],\n",
      "        [ 0.8000,  0.0948],\n",
      "        [ 0.8000, -0.2924],\n",
      "        [ 0.8000, -0.0681],\n",
      "        [ 0.8000, -0.0447],\n",
      "        [ 0.8000, -0.0392],\n",
      "        [ 0.8000, -0.4009],\n",
      "        [ 0.8000,  0.0790],\n",
      "        [ 0.8000, -0.0270],\n",
      "        [ 0.8000,  0.7568],\n",
      "        [ 0.8000,  1.2275],\n",
      "        [ 0.5700, -0.0952],\n",
      "        [ 0.8000, -0.4648],\n",
      "        [ 0.8000, -0.0829],\n",
      "        [ 0.8000, -0.0935],\n",
      "        [ 0.8000,  1.0782],\n",
      "        [ 0.8000, -0.5708],\n",
      "        [ 0.8000, -0.1664],\n",
      "        [ 0.8000, -0.1036],\n",
      "        [ 0.8000, -0.0722],\n",
      "        [ 0.8000, -0.0649],\n",
      "        [ 0.8000, -0.0859],\n",
      "        [ 0.8000, -0.1014],\n",
      "        [ 0.8000, -0.0851],\n",
      "        [ 0.8000, -0.0692],\n",
      "        [ 0.8000,  0.0086],\n",
      "        [ 0.8000, -0.0786],\n",
      "        [ 0.8000, -0.0152],\n",
      "        [ 0.8000, -0.0697],\n",
      "        [ 0.8000, -0.1136],\n",
      "        [ 0.8000,  0.0587],\n",
      "        [ 0.8000, -0.0125],\n",
      "        [ 0.8000, -0.0184],\n",
      "        [ 0.8000,  1.0711],\n",
      "        [ 0.8000, -0.3171],\n",
      "        [ 0.8000, -0.1778],\n",
      "        [ 0.8000, -0.0856],\n",
      "        [ 0.8000,  0.0750],\n",
      "        [ 0.8000, -0.1415],\n",
      "        [ 0.8000, -0.1243],\n",
      "        [ 0.8000, -0.0537],\n",
      "        [ 0.8000,  0.0346],\n",
      "        [ 0.8000,  0.0465],\n",
      "        [ 0.8000, -0.3858],\n",
      "        [ 0.8000,  0.0915],\n",
      "        [ 0.8000, -0.1081],\n",
      "        [ 0.8000, -0.0630],\n",
      "        [ 0.8000, -0.0127],\n",
      "        [ 0.8000, -0.0301],\n",
      "        [ 0.8000, -0.0855],\n",
      "        [ 0.8000,  0.1633],\n",
      "        [ 0.8000,  0.1646]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "# test dataloader\n",
    "lidar, non_lidar, actions = next(iter(train_loader))\n",
    "print(f\"Non lidar shape: {non_lidar.shape}\")\n",
    "print(f\"Lidar shape: {lidar.shape}\")\n",
    "# print size dataloader\n",
    "print(f\"Train loader size: {len(train_loader)}\")\n",
    "print(f\"Val loader size: {len(val_loader)}\")\n",
    "print(lidar, non_lidar, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2042, 1.2010, 1.2006,  ..., 0.7230, 0.7289, 0.7393],\n",
       "        [5.0000, 5.0000, 5.0000,  ..., 1.8720, 1.8806, 1.8984],\n",
       "        [4.3470, 4.5073, 4.7787,  ..., 0.6869, 0.7010, 0.8091],\n",
       "        ...,\n",
       "        [5.0000, 5.0000, 5.0000,  ..., 5.0000, 5.0000, 5.0000],\n",
       "        [1.0508, 1.0547, 1.0599,  ..., 5.0000, 5.0000, 5.0000],\n",
       "        [0.6421, 0.6455, 0.6493,  ..., 0.9102, 0.9169, 0.9384]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lidar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0088e+00, -3.5703e-02,  5.9112e+00, -5.7129e-01],\n",
       "        [ 9.8328e-01,  2.6551e-01,  3.7076e+00,  6.4741e+00],\n",
       "        [ 9.6028e-01,  2.8164e-01,  3.5545e+00,  4.2327e+00],\n",
       "        [ 9.8061e-01,  2.1264e-01,  5.1315e+00, -5.5955e+00],\n",
       "        [ 1.0209e+00,  3.8610e-02,  5.1080e+00, -4.9602e-01],\n",
       "        [ 1.0104e+00,  2.7528e-02,  6.7788e+00, -2.6475e-01],\n",
       "        [ 1.0004e+00, -5.7744e-02,  1.4542e+00, -1.6251e-01],\n",
       "        [ 1.0119e+00, -2.5100e-02,  3.0506e+00, -2.9924e-01],\n",
       "        [ 1.0069e+00, -1.2296e-01,  3.9403e+00, -1.7460e+00],\n",
       "        [ 1.0090e+00, -3.6122e-02,  7.7484e+00,  1.3032e-01],\n",
       "        [ 1.0080e+00, -1.3317e-02,  7.5919e+00, -4.8836e-01],\n",
       "        [ 1.0002e+00, -1.4965e-02,  8.9064e+00, -5.4051e-01],\n",
       "        [ 9.9914e-01,  5.2376e-02,  3.4837e+00,  4.0771e-01],\n",
       "        [ 1.0133e+00,  5.2077e-02,  6.4892e+00, -3.1805e+00],\n",
       "        [ 9.9290e-01, -1.7476e-01,  9.1501e+00, -2.2815e+00],\n",
       "        [ 1.0221e+00, -3.7916e-02,  6.0536e+00,  2.6381e+00],\n",
       "        [ 1.0132e+00,  2.1554e-02,  4.8650e+00, -5.9620e+00],\n",
       "        [ 1.0208e+00, -3.2034e-02,  2.1569e+00, -2.0510e-01],\n",
       "        [ 9.8783e-01, -2.3095e-01,  9.3185e+00, -2.5543e+00],\n",
       "        [ 1.0163e+00,  2.6597e-02,  3.0641e+00,  2.7689e-01],\n",
       "        [ 1.0194e+00, -1.8569e-02,  3.5326e+00, -3.1030e-01],\n",
       "        [ 9.2812e-01,  4.0370e-01,  7.2079e+00,  2.7026e+00],\n",
       "        [ 5.8466e-01,  8.2894e-01,  9.0175e+00,  1.8493e+00],\n",
       "        [ 1.0051e+00, -8.1195e-02,  9.8367e+00, -1.1837e+00],\n",
       "        [ 9.6387e-01, -2.6652e-01,  9.3919e+00,  4.0829e-01],\n",
       "        [ 1.0221e+00, -4.9108e-02,  1.3494e+00, -1.3721e-01],\n",
       "        [ 1.0143e+00, -4.1944e-02,  4.1394e+00, -1.8567e+00],\n",
       "        [ 8.4511e-01,  5.5641e-01,  3.5923e+00,  4.4006e+00],\n",
       "        [ 9.7460e-01, -3.1570e-01,  9.0821e+00, -3.3254e+00],\n",
       "        [ 1.0116e+00, -9.8198e-02,  9.4192e+00, -1.0825e+00],\n",
       "        [ 1.0092e+00, -5.9584e-02,  9.4674e+00, -5.9486e-01],\n",
       "        [ 1.0042e+00, -6.0068e-02,  3.5974e+00, -5.4265e-01],\n",
       "        [ 1.0087e+00,  2.3718e-02,  5.5580e+00,  5.1233e-01],\n",
       "        [ 1.0123e+00, -5.2790e-02,  7.8857e+00,  1.9171e+00],\n",
       "        [ 1.0190e+00, -6.4401e-02,  1.0429e+00, -7.3801e-02],\n",
       "        [ 1.0001e+00, -7.9665e-02,  6.7466e+00, -1.8980e+00],\n",
       "        [ 1.0006e+00, -7.2730e-02,  5.6946e+00,  5.1969e-01],\n",
       "        [ 1.0172e+00, -1.6333e-02,  7.6857e+00,  3.2575e-01],\n",
       "        [ 1.0231e+00, -5.5299e-02,  1.6526e+00, -1.6465e-01],\n",
       "        [ 1.0127e+00, -1.6862e-02,  2.7302e+00, -2.3087e-01],\n",
       "        [ 1.0081e+00, -4.3628e-02,  8.9231e+00, -1.0227e+00],\n",
       "        [ 1.0132e+00, -9.3155e-02,  6.7536e+00, -6.1629e-02],\n",
       "        [ 1.0033e+00,  2.3447e-02,  4.1229e+00, -2.2909e-01],\n",
       "        [ 1.0080e+00, -1.3892e-02,  3.0989e+00, -2.6336e-01],\n",
       "        [ 1.0109e+00, -1.9094e-02,  2.3763e+00, -2.3509e-01],\n",
       "        [ 8.7819e-01,  4.9778e-01,  4.5018e+00,  5.4920e+00],\n",
       "        [ 9.9255e-01, -1.6281e-01,  7.8612e+00,  4.1572e+00],\n",
       "        [ 1.0083e+00, -7.1334e-02,  7.6016e+00,  9.7430e-01],\n",
       "        [ 1.0005e+00, -5.3560e-02,  2.5890e+00, -3.2699e-01],\n",
       "        [ 1.0025e+00,  3.5403e-02,  9.4024e+00,  7.8580e-02],\n",
       "        [ 1.0153e+00, -1.1709e-01,  6.5032e+00, -1.4717e+00],\n",
       "        [ 9.9944e-01, -5.0965e-02,  6.6611e+00,  2.6347e+00],\n",
       "        [ 1.0032e+00, -3.5798e-02,  7.1484e+00, -8.6201e-01],\n",
       "        [ 1.0163e+00,  1.4144e-02,  1.6143e+00,  8.8878e-02],\n",
       "        [ 1.0027e+00,  1.2442e-02,  8.0081e+00, -8.9576e-01],\n",
       "        [ 9.9749e-01, -1.9110e-01,  8.9519e+00, -3.0526e+00],\n",
       "        [ 1.0121e+00,  6.6298e-02,  6.4713e+00,  1.9428e+00],\n",
       "        [ 1.0068e+00,  8.0103e-02,  7.5167e+00,  3.0626e+00],\n",
       "        [ 1.0173e+00, -3.3992e-02,  1.9945e+00,  1.0919e-02],\n",
       "        [ 1.0042e+00,  7.3841e-03,  8.4547e+00, -1.0662e+00],\n",
       "        [ 1.0158e+00, -2.1503e-02,  3.9775e+00, -3.4620e-01],\n",
       "        [ 1.0102e+00, -5.6275e-02,  2.1071e+00, -2.4635e-01],\n",
       "        [ 1.0102e+00, -1.1673e-01,  6.4456e+00, -4.2077e+00],\n",
       "        [ 9.9876e-01,  1.1287e-01,  7.1998e+00,  6.0675e-01]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_lidar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8000, -0.0439],\n",
       "        [ 0.8000,  0.0693],\n",
       "        [ 0.8000,  0.1975],\n",
       "        [ 0.8000,  0.5774],\n",
       "        [ 0.8000,  0.0427],\n",
       "        [ 0.8000,  0.0486],\n",
       "        [ 0.8000, -0.1114],\n",
       "        [ 0.8000, -0.0254],\n",
       "        [ 0.8000, -0.1851],\n",
       "        [ 0.8000, -0.0370],\n",
       "        [ 0.8000, -0.0192],\n",
       "        [ 0.8000, -0.0275],\n",
       "        [ 0.8000,  0.0937],\n",
       "        [ 0.8000,  0.0948],\n",
       "        [ 0.8000, -0.2924],\n",
       "        [ 0.8000, -0.0681],\n",
       "        [ 0.8000, -0.0447],\n",
       "        [ 0.8000, -0.0392],\n",
       "        [ 0.8000, -0.4009],\n",
       "        [ 0.8000,  0.0790],\n",
       "        [ 0.8000, -0.0270],\n",
       "        [ 0.8000,  0.7568],\n",
       "        [ 0.8000,  1.2275],\n",
       "        [ 0.5700, -0.0952],\n",
       "        [ 0.8000, -0.4648],\n",
       "        [ 0.8000, -0.0829],\n",
       "        [ 0.8000, -0.0935],\n",
       "        [ 0.8000,  1.0782],\n",
       "        [ 0.8000, -0.5708],\n",
       "        [ 0.8000, -0.1664],\n",
       "        [ 0.8000, -0.1036],\n",
       "        [ 0.8000, -0.0722],\n",
       "        [ 0.8000, -0.0649],\n",
       "        [ 0.8000, -0.0859],\n",
       "        [ 0.8000, -0.1014],\n",
       "        [ 0.8000, -0.0851],\n",
       "        [ 0.8000, -0.0692],\n",
       "        [ 0.8000,  0.0086],\n",
       "        [ 0.8000, -0.0786],\n",
       "        [ 0.8000, -0.0152],\n",
       "        [ 0.8000, -0.0697],\n",
       "        [ 0.8000, -0.1136],\n",
       "        [ 0.8000,  0.0587],\n",
       "        [ 0.8000, -0.0125],\n",
       "        [ 0.8000, -0.0184],\n",
       "        [ 0.8000,  1.0711],\n",
       "        [ 0.8000, -0.3171],\n",
       "        [ 0.8000, -0.1778],\n",
       "        [ 0.8000, -0.0856],\n",
       "        [ 0.8000,  0.0750],\n",
       "        [ 0.8000, -0.1415],\n",
       "        [ 0.8000, -0.1243],\n",
       "        [ 0.8000, -0.0537],\n",
       "        [ 0.8000,  0.0346],\n",
       "        [ 0.8000,  0.0465],\n",
       "        [ 0.8000, -0.3858],\n",
       "        [ 0.8000,  0.0915],\n",
       "        [ 0.8000, -0.1081],\n",
       "        [ 0.8000, -0.0630],\n",
       "        [ 0.8000, -0.0127],\n",
       "        [ 0.8000, -0.0301],\n",
       "        [ 0.8000, -0.0855],\n",
       "        [ 0.8000,  0.1633],\n",
       "        [ 0.8000,  0.1646]], dtype=torch.float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_lidar_features, num_non_lidar_features, num_actions, nframes=1):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.act_fea_cv1 = nn.Conv1d(\n",
    "            in_channels=nframes, out_channels=32, kernel_size=5, stride=2, padding=6, padding_mode='circular'\n",
    "        )\n",
    "        self.act_fea_cv2 = nn.Conv1d(\n",
    "            in_channels=32, out_channels=32, kernel_size=3, stride=2, padding=1\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            sample_input = torch.randn(1, nframes, num_lidar_features)\n",
    "            sample_output = self.act_fea_cv1(sample_input)\n",
    "            sample_output = self.act_fea_cv2(sample_output)\n",
    "            conv_output_size = sample_output.view(1, -1).shape[1]\n",
    "\n",
    "        # Calculate the output size of the CNN\n",
    "        self.fc1 = nn.Linear(conv_output_size, 64)\n",
    "        self.fc2 = nn.Linear(64 + num_non_lidar_features * nframes, 64)\n",
    "        self.fc3 = nn.Linear(64, num_actions)\n",
    "\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "\n",
    "    def forward(self, lidar, non_lidar):\n",
    "        feat = F.relu(self.act_fea_cv1(lidar))\n",
    "        feat = F.relu(self.act_fea_cv2(feat))\n",
    "        feat = feat.view(feat.shape[0], -1)\n",
    "        feat = F.relu(self.fc1(feat))\n",
    "        # feat = torch.cat((feat, non_lidar.view(non_lidar.shape[0], -1)), dim=-1)\n",
    "        feat = torch.cat((feat, non_lidar.flatten(start_dim=1)), dim=-1)\n",
    "        feat = F.relu(self.fc2(feat))\n",
    "        feat = self.fc3(feat)\n",
    "        return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a CustomLoss prioritizing the angular velocity\n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        # increase the loss of the second element of the prediction\n",
    "        # this is the angular velocity\n",
    "        loss = (pred - target) ** 2\n",
    "        loss[:, 1] *= 2\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "num_lidar_features = len(train_dataset.lidar_cols)\n",
    "num_non_lidar_features = len(train_dataset.non_lidar_cols)\n",
    "num_actions = len(train_dataset.actions_cols)\n",
    "model = CNNModel(num_lidar_features, num_non_lidar_features, num_actions)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Move the model and loss function to the GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "loss_fn = loss_fn.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, train_loader, loss_fn, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    for lidar, non_lidar, actions in tqdm(train_loader):\n",
    "        # Move the data to the device that is used\n",
    "        lidar = lidar.to(device).unsqueeze(1)\n",
    "        non_lidar = non_lidar.to(device).unsqueeze(1)\n",
    "        actions = actions.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        actions_pred = model(lidar.float(), non_lidar.float())\n",
    "        loss = loss_fn(actions_pred, actions.float())\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Save the loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # return the average loss for this epoch\n",
    "    return sum(losses)/len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, loss_fn):\n",
    "    model.eval()\n",
    "\n",
    "    losses = []\n",
    "    for lidar, non_lidar, actions in tqdm(test_loader):\n",
    "        # Move the data to the device that is used\n",
    "        lidar = lidar.to(device).unsqueeze(1)\n",
    "        non_lidar = non_lidar.to(device).unsqueeze(1)\n",
    "        actions = actions.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        actions_pred = model(lidar.float(), non_lidar.float())\n",
    "        loss = loss_fn(actions_pred, actions.float())\n",
    "\n",
    "        # Save the loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # return the average loss for this epoch\n",
    "    return sum(losses)/len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1350/1350 [00:07<00:00, 192.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random val loss: 0.5138106651769744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:35<00:00, 157.48it/s]\n",
      "100%|██████████| 1350/1350 [00:04<00:00, 334.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 0.0387804846445768 | Val Loss: 0.017080062226493654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:21<00:00, 259.19it/s]\n",
      "100%|██████████| 1350/1350 [00:01<00:00, 762.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 | Train Loss: 0.02285634203275531 | Val Loss: 0.013792185841798697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:47<00:00, 117.17it/s]\n",
      "100%|██████████| 1350/1350 [00:09<00:00, 135.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 | Train Loss: 0.018761545282618287 | Val Loss: 0.011999342738892194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:23<00:00, 241.95it/s]\n",
      "100%|██████████| 1350/1350 [00:01<00:00, 731.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 | Train Loss: 0.016143891194418523 | Val Loss: 0.010430850670263343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:24<00:00, 230.83it/s]\n",
      "100%|██████████| 1350/1350 [00:03<00:00, 358.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 | Train Loss: 0.014307433413308219 | Val Loss: 0.009382476500026382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:33<00:00, 164.96it/s]\n",
      "100%|██████████| 1350/1350 [00:01<00:00, 771.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 | Train Loss: 0.013011338427568764 | Val Loss: 0.008667857120750274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:20<00:00, 268.38it/s]\n",
      "100%|██████████| 1350/1350 [00:01<00:00, 702.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 | Train Loss: 0.012065480703682846 | Val Loss: 0.0080758580337257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:19<00:00, 283.79it/s]\n",
      "100%|██████████| 1350/1350 [00:02<00:00, 651.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 | Train Loss: 0.011381997310933478 | Val Loss: 0.007871439822184686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:20<00:00, 271.07it/s]\n",
      "100%|██████████| 1350/1350 [00:01<00:00, 861.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 | Train Loss: 0.010872564355874689 | Val Loss: 0.0075036386478017515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:19<00:00, 283.25it/s]\n",
      "100%|██████████| 1350/1350 [00:01<00:00, 772.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 | Train Loss: 0.010460491435290306 | Val Loss: 0.007437619019423167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:22<00:00, 247.79it/s]\n",
      "100%|██████████| 1350/1350 [00:01<00:00, 740.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 | Train Loss: 0.010123426232540606 | Val Loss: 0.0072810020091775285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:20<00:00, 274.26it/s]\n",
      "100%|██████████| 1350/1350 [00:01<00:00, 697.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 | Train Loss: 0.009843215866413929 | Val Loss: 0.007161839282818147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:19<00:00, 287.98it/s]\n",
      "100%|██████████| 1350/1350 [00:02<00:00, 560.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 | Train Loss: 0.009602690890162184 | Val Loss: 0.006881576156045884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:21<00:00, 256.37it/s]\n",
      "100%|██████████| 1350/1350 [00:01<00:00, 744.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 | Train Loss: 0.009379438248448937 | Val Loss: 0.006859536994220603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:19<00:00, 288.03it/s]\n",
      "100%|██████████| 1350/1350 [00:02<00:00, 638.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 | Train Loss: 0.009184386132817421 | Val Loss: 0.006882030374685268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:23<00:00, 241.93it/s]\n",
      "100%|██████████| 1350/1350 [00:02<00:00, 606.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 | Train Loss: 0.008993755918815943 | Val Loss: 0.006812933875976509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:26<00:00, 212.17it/s]\n",
      "100%|██████████| 1350/1350 [00:02<00:00, 642.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 | Train Loss: 0.008832201669395382 | Val Loss: 0.00683390654817534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:20<00:00, 277.07it/s]\n",
      "100%|██████████| 1350/1350 [00:01<00:00, 786.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 | Train Loss: 0.008685829098362803 | Val Loss: 0.006917421759892561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:17<00:00, 318.58it/s]\n",
      "100%|██████████| 1350/1350 [00:01<00:00, 789.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 | Train Loss: 0.008547832600878665 | Val Loss: 0.006644121091540675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:17<00:00, 311.99it/s]\n",
      "100%|██████████| 1350/1350 [00:01<00:00, 735.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 | Train Loss: 0.008424441207630355 | Val Loss: 0.006666546161201646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:17<00:00, 326.86it/s]\n",
      "100%|██████████| 1350/1350 [00:01<00:00, 771.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 | Train Loss: 0.008286525341532987 | Val Loss: 0.006782489792126903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:17<00:00, 327.57it/s]\n",
      "100%|██████████| 1350/1350 [00:01<00:00, 754.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 | Train Loss: 0.008181004540618925 | Val Loss: 0.006631491503519808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:16<00:00, 331.02it/s]\n",
      "100%|██████████| 1350/1350 [00:01<00:00, 791.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 | Train Loss: 0.008074728711204486 | Val Loss: 0.00664151814963757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:16<00:00, 348.15it/s]\n",
      "100%|██████████| 1350/1350 [00:01<00:00, 776.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 | Train Loss: 0.00796195498232369 | Val Loss: 0.006683722158518827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:16<00:00, 346.56it/s]\n",
      "100%|██████████| 1350/1350 [00:01<00:00, 761.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 | Train Loss: 0.00786638151071852 | Val Loss: 0.006703142836017327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping due to no improvement after 3 epochs.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "random_val_loss = test_model(model, val_loader, loss_fn)\n",
    "print(\"Random val loss:\", random_val_loss)\n",
    "sys.stdout.flush()\n",
    "\n",
    "cnn_train_losses = []\n",
    "cnn_val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "patience = 3\n",
    "no_improve_epochs = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss = train_model(model, train_loader, loss_fn, optimizer)\n",
    "    val_loss = test_model(model, val_loader, loss_fn)\n",
    "    cnn_train_losses.append(train_loss)\n",
    "    cnn_val_losses.append(val_loss)\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} | Train Loss: {train_loss} | Val Loss: {val_loss}\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        no_improve_epochs = 0\n",
    "    else:\n",
    "        no_improve_epochs += 1\n",
    "        if no_improve_epochs >= patience:\n",
    "            print(\"Early stopping due to no improvement after {} epochs.\".format(patience))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(cnn_train_losses, label='Train Loss')\n",
    "plt.plot(cnn_val_losses, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), 'models/cnn_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, loss_fn):\n",
    "    model.eval()\n",
    "\n",
    "    losses = []\n",
    "    for lidar, non_lidar, actions in tqdm(test_loader):\n",
    "        # Move the data to the device that is used\n",
    "        lidar = lidar.to(device).unsqueeze(1)\n",
    "        non_lidar = non_lidar.to(device).unsqueeze(1)\n",
    "        actions = actions.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        actions_pred = model(lidar.float(), non_lidar.float())\n",
    "        loss = loss_fn(actions_pred, actions.float())\n",
    "\n",
    "        if loss.item() > 0.1:\n",
    "            print(\"---------------------------\")\n",
    "            print(\"Loss:\", loss.item())\n",
    "            print(\"Predicted:\", actions_pred)\n",
    "            print(\"Actual:\", actions)\n",
    "            print(\"Non lidar:\", non_lidar)\n",
    "            continue\n",
    "\n",
    "        # Save the loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # return the average loss for this epoch\n",
    "    return sum(losses)/len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 422/1789 [00:00<00:00, 2303.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Loss: 0.2144078016281128\n",
      "Predicted: tensor([[0.7366, 0.1176]], grad_fn=<AddmmBackward0>)\n",
      "Actual: tensor([[0.0900, 0.0139]], dtype=torch.float64)\n",
      "Non lidar: tensor([[[0.9975, 0.0734, 9.9962, 0.2351]]], dtype=torch.float64)\n",
      "---------------------------\n",
      "Loss: 0.199073925614357\n",
      "Predicted: tensor([[0.7432, 0.1173]], grad_fn=<AddmmBackward0>)\n",
      "Actual: tensor([[0.1200, 0.0186]], dtype=torch.float64)\n",
      "Non lidar: tensor([[[1.0212, 0.0739, 9.9949, 0.2343]]], dtype=torch.float64)\n",
      "---------------------------\n",
      "Loss: 0.1799062341451645\n",
      "Predicted: tensor([[0.7424, 0.1174]], grad_fn=<AddmmBackward0>)\n",
      "Actual: tensor([[0.1500, 0.0232]], dtype=torch.float64)\n",
      "Non lidar: tensor([[[1.0192, 0.0739, 9.9929, 0.2339]]], dtype=torch.float64)\n",
      "---------------------------\n",
      "Loss: 0.16288241744041443\n",
      "Predicted: tensor([[0.7412, 0.1153]], grad_fn=<AddmmBackward0>)\n",
      "Actual: tensor([[0.1800, 0.0112]], dtype=torch.float64)\n",
      "Non lidar: tensor([[[1.0166, 0.0738, 9.9903, 0.2326]]], dtype=torch.float64)\n",
      "---------------------------\n",
      "Loss: 0.14599967002868652\n",
      "Predicted: tensor([[0.7406, 0.1155]], grad_fn=<AddmmBackward0>)\n",
      "Actual: tensor([[0.2100, 0.0130]], dtype=torch.float64)\n",
      "Non lidar: tensor([[[1.0134, 0.0737, 9.9871, 0.2320]]], dtype=torch.float64)\n",
      "---------------------------\n",
      "Loss: 0.1265416443347931\n",
      "Predicted: tensor([[0.7413, 0.0576]], grad_fn=<AddmmBackward0>)\n",
      "Actual: tensor([[0.2400, 0.0149]], dtype=torch.float64)\n",
      "Non lidar: tensor([[[1.0107, 0.0238, 9.9833, 0.2326]]], dtype=torch.float64)\n",
      "---------------------------\n",
      "Loss: 0.11154171824455261\n",
      "Predicted: tensor([[0.7405, 0.0577]], grad_fn=<AddmmBackward0>)\n",
      "Actual: tensor([[0.2700, 0.0167]], dtype=torch.float64)\n",
      "Non lidar: tensor([[[1.0063, 0.0238, 9.9789, 0.2325]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1789/1789 [00:00<00:00, 2780.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Loss: 0.18309138715267181\n",
      "Predicted: tensor([[0.7569, 0.2230]], grad_fn=<AddmmBackward0>)\n",
      "Actual: tensor([[0.1800, 0.0403]], dtype=torch.float64)\n",
      "Non lidar: tensor([[[1.0119, 0.1120, 9.9331, 1.0930]]], dtype=torch.float64)\n",
      "---------------------------\n",
      "Loss: 0.16416116058826447\n",
      "Predicted: tensor([[0.7556, 0.2220]], grad_fn=<AddmmBackward0>)\n",
      "Actual: tensor([[0.2100, 0.0470]], dtype=torch.float64)\n",
      "Non lidar: tensor([[[1.0088, 0.1116, 9.9304, 1.0889]]], dtype=torch.float64)\n",
      "---------------------------\n",
      "Loss: 0.14629240334033966\n",
      "Predicted: tensor([[0.7545, 0.2207]], grad_fn=<AddmmBackward0>)\n",
      "Actual: tensor([[0.2400, 0.0537]], dtype=torch.float64)\n",
      "Non lidar: tensor([[[1.0051, 0.1109, 9.9274, 1.0827]]], dtype=torch.float64)\n",
      "---------------------------\n",
      "Loss: 0.12980231642723083\n",
      "Predicted: tensor([[0.7552, 0.2161]], grad_fn=<AddmmBackward0>)\n",
      "Actual: tensor([[0.2700, 0.0605]], dtype=torch.float64)\n",
      "Non lidar: tensor([[[1.0009, 0.1103, 9.9237, 1.0763]]], dtype=torch.float64)\n",
      "---------------------------\n",
      "Loss: 0.10989125818014145\n",
      "Predicted: tensor([[0.7461, 0.2112]], grad_fn=<AddmmBackward0>)\n",
      "Actual: tensor([[0.3000, 0.0672]], dtype=torch.float64)\n",
      "Non lidar: tensor([[[0.9960, 0.1094, 9.9197, 1.0677]]], dtype=torch.float64)\n",
      "Final val loss: 0.003770924425007305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load file and check MSELoss\n",
    "model = CNNModel(num_lidar_features, num_non_lidar_features, num_actions)\n",
    "model.load_state_dict(torch.load('models/cnn_model.pth', map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "device = 'cpu'\n",
    "\n",
    "# take world idx 0 as example\n",
    "dataset = KULBarnDataset(df[df['world_idx'] == 0], \"val\")\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "final_val_loss = test_model(model, loader, loss_fn)\n",
    "print(\"Final val loss:\", final_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_dim,\n",
    "            num_heads,\n",
    "            dropout=0.0,\n",
    "            bias=False,\n",
    "            encoder_decoder_attention=False,\n",
    "            causal=False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        self.head_dim = input_dim // num_heads\n",
    "        self.encoder_decoder_attention = encoder_decoder_attention\n",
    "        self.causal = causal\n",
    "        self.k_proj = nn.Linear(input_dim, input_dim, bias=bias)\n",
    "        self.v_proj = nn.Linear(input_dim, input_dim, bias=bias)\n",
    "        self.q_proj = nn.Linear(input_dim, input_dim, bias=bias)\n",
    "        self.out_proj = nn.Linear(input_dim, input_dim, bias=bias)\n",
    "\n",
    "    def transpose_for_scores(self, x):\n",
    "        new_x_shape = x.size()[:-1] + (self.num_heads, self.head_dim,)\n",
    "        x = x.view(*new_x_shape)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "\n",
    "    def multi_head_scaled_dot_product(self,\n",
    "                                      query: torch.Tensor,\n",
    "                                      key: torch.Tensor,\n",
    "                                      value: torch.Tensor,\n",
    "                                      attention_mask: torch.BoolTensor):\n",
    "        attn_weights = torch.matmul(query, key.transpose(-1, -2) / math.sqrt(self.input_dim))\n",
    "        if attention_mask is not None:\n",
    "            if self.causal:\n",
    "                attn_weights = attn_weights.masked_fill(attention_mask.unsqueeze(0).unsqueeze(1), float(\"-inf\"))\n",
    "            else:\n",
    "                attn_weights = attn_weights.masked_fill(attention_mask.unsqueeze(1).unsqueeze(2), float(\"-inf\"))\n",
    "        attn_weights = F.softmax(attn_weights, dim=-1)\n",
    "        attn_probs = F.dropout(attn_weights, p=self.dropout, training=self.training)\n",
    "        attn_output = torch.matmul(attn_probs, value)\n",
    "        attn_output = attn_output.permute(0, 2, 1, 3).contiguous()\n",
    "        concat_attn_output_shape = attn_output.size()[:-2] + (self.input_dim,)\n",
    "        attn_output = attn_output.view(*concat_attn_output_shape)\n",
    "        attn_output = self.out_proj(attn_output)\n",
    "        return attn_output, attn_weights\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            query: torch.Tensor,\n",
    "            key: torch.Tensor,\n",
    "            attention_mask: torch.BoolTensor):\n",
    "        q = self.q_proj(query)\n",
    "        if self.encoder_decoder_attention:\n",
    "            k = self.k_proj(key)\n",
    "            v = self.v_proj(key)\n",
    "        else:\n",
    "            k = self.k_proj(query)\n",
    "            v = self.v_proj(query)\n",
    "        q = self.transpose_for_scores(q)\n",
    "        k = self.transpose_for_scores(k)\n",
    "        v = self.transpose_for_scores(v)\n",
    "\n",
    "        attn_output, attn_weights = self.multi_head_scaled_dot_product(q, k, v, attention_mask)\n",
    "        return attn_output, attn_weights\n",
    "\n",
    "\n",
    "class PositionWiseFeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim: int, d_ff: int, dropout: float = 0.1):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        self.w_1 = nn.Linear(input_dim, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, input_dim)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.activation(self.w_1(x))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.w_2(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        return x + residual\n",
    "\n",
    "\n",
    "class EmbeddingLidar(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.len_lidar = config.lidar_dim\n",
    "        self.num_patch = config.num_patch\n",
    "        self.dim_patch = self.len_lidar // self.num_patch\n",
    "        self.model_dim = config.model_dim\n",
    "        self.dropout = config.dropout\n",
    "        self.pos_embed = nn.Parameter(torch.randn(self.num_patch, self.model_dim))\n",
    "\n",
    "        self.linear = nn.Linear(self.dim_patch, self.model_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = inputs.view([-1, self.num_patch, self.dim_patch])\n",
    "        x = self.linear(x)\n",
    "        x = x + self.pos_embed\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.input_dim = config.input_dim\n",
    "        self.ffn_dim = config.ffn_dim\n",
    "        self.self_attn = MultiHeadAttention(\n",
    "            input_dim=self.input_dim,\n",
    "            num_heads=config.attention_heads,\n",
    "            dropout=config.attention_dropout)\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(self.input_dim)\n",
    "        self.dropout = config.dropout\n",
    "        self.activation_fn = nn.ReLU()\n",
    "        self.PositionWiseFeedForward = PositionWiseFeedForward(self.input_dim, self.ffn_dim, config.dropout)\n",
    "        self.final_layer_norm = nn.LayerNorm(self.input_dim)\n",
    "\n",
    "    def forward(self, x, encoder_padding_mask):\n",
    "        residual = x\n",
    "        x, attn_weights = self.self_attn(query=x, key=x, attention_mask=encoder_padding_mask)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = residual + x\n",
    "        x = self.self_attn_layer_norm(x)\n",
    "        x = self.PositionWiseFeedForward(x)\n",
    "        x = self.final_layer_norm(x)\n",
    "        return x, attn_weights\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dropout = config.dropout\n",
    "\n",
    "        self.embedding = EmbeddingLidar(config)\n",
    "\n",
    "        self.layers = nn.ModuleList([EncoderLayer(config) for _ in range(config.encoder_layers)])\n",
    "\n",
    "    def forward(self, inputs, attention_mask=None):\n",
    "        x = self.embedding(inputs)\n",
    "        self_attn_scores = []\n",
    "        for encoder_layer in self.layers:\n",
    "            x, attn = encoder_layer(x, attention_mask)\n",
    "            self_attn_scores.append(attn.detach())\n",
    "\n",
    "        return x, self_attn_scores\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.input_dim = config.input_dim\n",
    "        self.ffn_dim = config.ffn_dim\n",
    "        self.dropout = config.dropout\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(self.input_dim)\n",
    "        self.encoder_attn = MultiHeadAttention(\n",
    "            input_dim=self.input_dim,\n",
    "            num_heads=config.attention_heads,\n",
    "            dropout=config.attention_dropout,\n",
    "            encoder_decoder_attention=True,\n",
    "        )\n",
    "        self.encoder_attn_layer_norm = nn.LayerNorm(self.input_dim)\n",
    "        self.PositionWiseFeedForward = PositionWiseFeedForward(self.input_dim, self.ffn_dim, config.dropout)\n",
    "        self.final_layer_norm = nn.LayerNorm(self.input_dim)\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            x,\n",
    "            encoder_hidden_states,\n",
    "            encoder_attention_mask=None,\n",
    "    ):\n",
    "        residual = x\n",
    "        x, cross_attn_weights = self.encoder_attn(\n",
    "            query=x,\n",
    "            key=encoder_hidden_states,\n",
    "            attention_mask=encoder_attention_mask,\n",
    "        )\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = residual + x\n",
    "        x = self.encoder_attn_layer_norm(x)\n",
    "        x = self.PositionWiseFeedForward(x)\n",
    "        x = self.final_layer_norm(x)\n",
    "\n",
    "        return (\n",
    "            x,\n",
    "            cross_attn_weights,\n",
    "        )\n",
    "    \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dropout = config.dropout\n",
    "        self.model_dim = config.model_dim\n",
    "        self.linear = nn.Linear(1, self.model_dim)\n",
    "        self.layers = nn.ModuleList([DecoderLayer(config) for _ in range(config.decoder_layers)])\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            inputs,\n",
    "            encoder_hidden_states,\n",
    "    ):\n",
    "        x = inputs\n",
    "        x = self.linear(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        cross_attention_scores = []\n",
    "        for idx, decoder_layer in enumerate(self.layers):\n",
    "            x, layer_cross_attn = decoder_layer(\n",
    "                x,\n",
    "                encoder_hidden_states,\n",
    "            )\n",
    "            cross_attention_scores.append(layer_cross_attn.detach())\n",
    "        return x, cross_attention_scores\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.non_lidar_dim = config.non_lidar_dim\n",
    "        self.model_dim = config.model_dim\n",
    "        self.encoder = Encoder(config)\n",
    "        self.decoder = Decoder(config)\n",
    "\n",
    "        self.prediction_head = nn.Linear(self.model_dim * self.non_lidar_dim, 2)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                if 'weight' in name:\n",
    "                    nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "                else:\n",
    "                    nn.init.constant_(param.data, 0)\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        encoder_output, encoder_attention_scores = self.encoder(\n",
    "            inputs=src\n",
    "        )\n",
    "        decoder_output, decoder_attention_scores = self.decoder(\n",
    "            trg,\n",
    "            encoder_output\n",
    "        )\n",
    "        decoder_output = decoder_output.view(-1, self.model_dim * self.non_lidar_dim)\n",
    "        decoder_output = self.prediction_head(decoder_output)\n",
    "        \n",
    "        return decoder_output, encoder_attention_scores, decoder_attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, loss_fn, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    for lidar, non_lidar, actions in tqdm(train_loader):\n",
    "        lidar = lidar.to(device).unsqueeze(-1)\n",
    "        non_lidar = non_lidar.to(device).unsqueeze(-1)\n",
    "        actions = actions.to(device)\n",
    "\n",
    "        actions_pred, _, _ = model(lidar.float(), non_lidar.float())\n",
    "        loss = loss_fn(actions_pred, actions.float())\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Save the loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # return the average loss for this epoch\n",
    "    return sum(losses)/len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, loss_fn):\n",
    "    model.eval()\n",
    "\n",
    "    losses = []\n",
    "    for lidar, non_lidar, actions in tqdm(test_loader):\n",
    "        lidar = lidar.to(device).unsqueeze(-1)\n",
    "        non_lidar = non_lidar.to(device).unsqueeze(-1)\n",
    "        actions = actions.to(device)\n",
    "\n",
    "        actions_pred, _, _ = model(lidar.float(), non_lidar.float())\n",
    "\n",
    "        loss = loss_fn(actions_pred, actions.float())\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # return the average loss for this epoch\n",
    "    return sum(losses)/len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import easydict\n",
    "\n",
    "# Initialize the model\n",
    "num_lidar_features = len(train_dataset.lidar_cols)\n",
    "num_non_lidar_features = len(train_dataset.non_lidar_cols)\n",
    "num_actions = len(train_dataset.actions_cols)\n",
    "\n",
    "config_dict = easydict.EasyDict({\n",
    "    \"input_dim\": 32,\n",
    "    \"num_patch\": 36,\n",
    "    \"model_dim\": 32,\n",
    "    \"ffn_dim\": 256,\n",
    "    \"attention_heads\": 4,\n",
    "    \"attention_dropout\": 0.0,\n",
    "    \"dropout\": 0.5,\n",
    "    \"encoder_layers\": 2,\n",
    "    \"decoder_layers\": 2,\n",
    "    \"lidar_dim\": 360,\n",
    "    \"non_lidar_dim\": 4,\n",
    "    \"device\": \"cpu\",\n",
    "})\n",
    "\n",
    "model = Transformer(config_dict)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Move the model and loss function to the GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "loss_fn = loss_fn.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1350/1350 [00:04<00:00, 270.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random val loss: 0.3473640583841889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5573/5573 [00:52<00:00, 105.26it/s]\n",
      "100%|██████████| 1350/1350 [00:04<00:00, 284.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 | Train Loss: 0.14920923888744148 | Val Loss: 0.031456381092624115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:52<00:00, 105.75it/s]\n",
      "100%|██████████| 1350/1350 [00:04<00:00, 281.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 | Train Loss: 0.037344926524698126 | Val Loss: 0.019525746384633412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:53<00:00, 104.22it/s]\n",
      "100%|██████████| 1350/1350 [00:04<00:00, 300.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 | Train Loss: 0.02536240219196718 | Val Loss: 0.013565705831300606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:53<00:00, 103.29it/s]\n",
      "100%|██████████| 1350/1350 [00:04<00:00, 310.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 | Train Loss: 0.018067979336278062 | Val Loss: 0.01118924979655141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:47<00:00, 118.15it/s]\n",
      "100%|██████████| 1350/1350 [00:04<00:00, 328.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 | Train Loss: 0.015180359162431508 | Val Loss: 0.01107690118615412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:47<00:00, 117.98it/s]\n",
      "100%|██████████| 1350/1350 [00:04<00:00, 312.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 | Train Loss: 0.014210040538224012 | Val Loss: 0.010104251321301692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:48<00:00, 115.05it/s]\n",
      "100%|██████████| 1350/1350 [00:04<00:00, 278.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 | Train Loss: 0.0137784619611644 | Val Loss: 0.010016611613143512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:50<00:00, 111.19it/s]\n",
      "100%|██████████| 1350/1350 [00:04<00:00, 307.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 | Train Loss: 0.01345786269310569 | Val Loss: 0.009253777345271642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:48<00:00, 116.07it/s]\n",
      "100%|██████████| 1350/1350 [00:04<00:00, 310.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 | Train Loss: 0.013239931278564931 | Val Loss: 0.008174212051499463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:48<00:00, 114.94it/s]\n",
      "100%|██████████| 1350/1350 [00:04<00:00, 316.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 | Train Loss: 0.013134188367045177 | Val Loss: 0.007810861113507767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:47<00:00, 116.74it/s]\n",
      "100%|██████████| 1350/1350 [00:04<00:00, 310.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 | Train Loss: 0.012954054891491781 | Val Loss: 0.007745747000618495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:47<00:00, 117.01it/s]\n",
      "100%|██████████| 1350/1350 [00:04<00:00, 277.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 | Train Loss: 0.01287081176628991 | Val Loss: 0.00851207364837777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:55<00:00, 99.84it/s] \n",
      "100%|██████████| 1350/1350 [00:05<00:00, 262.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 | Train Loss: 0.012719721833117629 | Val Loss: 0.008065065815850782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5573/5573 [00:55<00:00, 100.78it/s]\n",
      "100%|██████████| 1350/1350 [00:04<00:00, 294.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 | Train Loss: 0.012653488568005649 | Val Loss: 0.008941138371937322\n",
      "Early stopping due to no improvement after 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "random_val_loss = test_model(model, val_loader, loss_fn)\n",
    "print(\"Random val loss:\", random_val_loss)\n",
    "\n",
    "transformer_train_losses = []\n",
    "transformer_val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "patience = 3\n",
    "no_improve_epochs = 0\n",
    "save_every = 5\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    train_loss = train_model(model, train_loader, loss_fn, optimizer)\n",
    "    val_loss = test_model(model, val_loader, loss_fn)\n",
    "    transformer_train_losses.append(train_loss)\n",
    "    transformer_val_losses.append(val_loss)\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} | Train Loss: {train_loss} | Val Loss: {val_loss}\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        no_improve_epochs = 0\n",
    "    else:\n",
    "        no_improve_epochs += 1\n",
    "        if no_improve_epochs >= patience:\n",
    "            print(\"Early stopping due to no improvement after {} epochs.\".format(patience))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(transformer_train_losses, label='Transformer Train Loss')  \n",
    "plt.plot(transformer_val_losses, label='Transformer Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), 'models/transformer_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, loss_fn):\n",
    "    model.eval()\n",
    "\n",
    "    losses = []\n",
    "    for lidar, non_lidar, actions in tqdm(test_loader):\n",
    "        # Move the data to the device that is used\n",
    "        lidar = lidar.to(device).unsqueeze(-1)\n",
    "        non_lidar = non_lidar.to(device).unsqueeze(-1)\n",
    "        actions = actions.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        actions_pred, _, _ = model(lidar.float(), non_lidar.float())        \n",
    "        loss = loss_fn(actions_pred, actions.float())\n",
    "        if loss.item() > 0.01:\n",
    "            print(actions_pred - actions)\n",
    "            print(loss)\n",
    "\n",
    "        # Save the loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # return the average loss for this epoch\n",
    "    return sum(losses)/len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.7221e-01,  1.0194e-01],\n",
      "        [ 6.4511e-01,  9.7106e-02],\n",
      "        [ 6.1486e-01,  9.2488e-02],\n",
      "        [ 5.8452e-01,  1.0445e-01],\n",
      "        [ 5.5412e-01,  1.0261e-01],\n",
      "        [ 5.2339e-01,  3.6847e-02],\n",
      "        [ 4.9283e-01,  3.5109e-02],\n",
      "        [ 4.6220e-01,  3.3313e-02],\n",
      "        [ 4.3457e-01,  3.1314e-02],\n",
      "        [ 4.0377e-01,  2.9532e-02],\n",
      "        [ 3.7293e-01,  2.7730e-02],\n",
      "        [ 3.4185e-01,  2.5696e-02],\n",
      "        [ 3.1384e-01,  2.3023e-02],\n",
      "        [ 2.8273e-01,  2.0897e-02],\n",
      "        [ 2.5458e-01,  1.8663e-02],\n",
      "        [ 2.2335e-01,  1.6294e-02],\n",
      "        [ 1.9196e-01,  1.4176e-02],\n",
      "        [ 1.6363e-01,  1.1926e-02],\n",
      "        [ 1.3215e-01,  1.8920e-02],\n",
      "        [ 1.0369e-01,  1.6965e-02],\n",
      "        [ 7.2044e-02,  1.5086e-02],\n",
      "        [ 4.3553e-02,  1.3852e-02],\n",
      "        [ 1.1833e-02,  1.2782e-02],\n",
      "        [-1.6883e-02,  1.1512e-02],\n",
      "        [-3.5603e-02,  1.1212e-02],\n",
      "        [-3.7498e-02, -3.5586e-04],\n",
      "        [-3.6418e-02, -2.6153e-05],\n",
      "        [-3.8480e-02, -1.7361e-04],\n",
      "        [-3.7407e-02, -2.3453e-03],\n",
      "        [-3.6641e-02, -3.9705e-03],\n",
      "        [-3.8671e-02,  8.0007e-03],\n",
      "        [-3.7702e-02,  6.5322e-03],\n",
      "        [-3.6824e-02,  1.4559e-02],\n",
      "        [-3.8801e-02,  1.3917e-02],\n",
      "        [-3.7764e-02,  1.3068e-02],\n",
      "        [-3.6773e-02,  1.6167e-02],\n",
      "        [-3.8733e-02,  1.5815e-02],\n",
      "        [-3.7654e-02,  1.5089e-02],\n",
      "        [-3.9602e-02,  2.2551e-02],\n",
      "        [-3.8587e-02,  2.1823e-02],\n",
      "        [-3.7383e-02,  2.1230e-02],\n",
      "        [-3.9397e-02,  2.1448e-02],\n",
      "        [-3.8209e-02,  2.0781e-02],\n",
      "        [-3.7148e-02,  2.0331e-02],\n",
      "        [-3.9133e-02,  2.0345e-02],\n",
      "        [-3.8040e-02,  2.0514e-02],\n",
      "        [-3.6949e-02,  2.0044e-02],\n",
      "        [-3.8770e-02,  2.0240e-02],\n",
      "        [-3.7766e-02,  1.9507e-02],\n",
      "        [-3.6659e-02,  1.9074e-02],\n",
      "        [-3.8624e-02,  1.9320e-02],\n",
      "        [-3.7644e-02,  1.8689e-02],\n",
      "        [-3.9716e-02,  1.8776e-02],\n",
      "        [-3.8457e-02,  1.8496e-02],\n",
      "        [-3.7347e-02,  1.7582e-02],\n",
      "        [-3.9466e-02,  1.7606e-02],\n",
      "        [-3.8244e-02,  1.7408e-02],\n",
      "        [-3.7071e-02,  1.7136e-02],\n",
      "        [-3.8970e-02,  2.3717e-02],\n",
      "        [-3.7857e-02,  2.2739e-02],\n",
      "        [-3.6605e-02,  2.3133e-02],\n",
      "        [-3.8568e-02,  2.3535e-02],\n",
      "        [-3.7553e-02,  2.2731e-02],\n",
      "        [-3.9546e-02,  2.2960e-02]], dtype=torch.float64,\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor(0.0293, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 11/28 [00:00<00:00, 103.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1027,  0.0530],\n",
      "        [-0.1069,  0.0990],\n",
      "        [-0.1044,  0.1584],\n",
      "        [-0.0724,  0.2642],\n",
      "        [-0.0597, -0.0964],\n",
      "        [-0.0584, -0.0080],\n",
      "        [-0.0572, -0.2394],\n",
      "        [-0.0530, -0.2378],\n",
      "        [-0.0540, -0.2034],\n",
      "        [-0.0478, -0.1956],\n",
      "        [-0.0447, -0.1978],\n",
      "        [-0.0459, -0.2825],\n",
      "        [-0.0438, -0.1538],\n",
      "        [-0.0433, -0.1261],\n",
      "        [-0.0444, -0.1249],\n",
      "        [-0.0434, -0.2561],\n",
      "        [-0.0459, -0.2257],\n",
      "        [-0.0388, -0.1332],\n",
      "        [-0.0349, -0.1592],\n",
      "        [-0.0291, -0.1667],\n",
      "        [-0.0276, -0.2913],\n",
      "        [-0.0247, -0.3084],\n",
      "        [-0.0241, -0.1633],\n",
      "        [-0.0237, -0.1865],\n",
      "        [-0.0237, -0.1817],\n",
      "        [-0.0204, -0.2099],\n",
      "        [-0.0203, -0.1807],\n",
      "        [-0.0243, -0.2180],\n",
      "        [-0.0311, -0.2164],\n",
      "        [-0.0394, -0.1694],\n",
      "        [-0.0430, -0.1446],\n",
      "        [-0.0464, -0.0703],\n",
      "        [-0.0205, -0.0976],\n",
      "        [-0.0269, -0.1410],\n",
      "        [-0.0357, -0.2586],\n",
      "        [-0.0430, -0.1636],\n",
      "        [-0.0468, -0.0816],\n",
      "        [-0.0365, -0.1213],\n",
      "        [-0.0256, -0.0875],\n",
      "        [-0.0356, -0.2238],\n",
      "        [-0.0465, -0.1187],\n",
      "        [-0.0614,  0.0440],\n",
      "        [-0.0357,  0.1290],\n",
      "        [-0.0241,  0.0486],\n",
      "        [-0.0351,  0.0647],\n",
      "        [-0.0436,  0.1474],\n",
      "        [-0.0521,  0.1859],\n",
      "        [-0.0662,  0.0685],\n",
      "        [-0.0103, -0.1022],\n",
      "        [-0.0169, -0.0492],\n",
      "        [-0.0221,  0.0453],\n",
      "        [-0.0247,  0.1251],\n",
      "        [-0.0123,  0.0149],\n",
      "        [-0.0113,  0.0710],\n",
      "        [-0.0097,  0.0925],\n",
      "        [-0.0077,  0.1385],\n",
      "        [-0.0178,  0.0467],\n",
      "        [-0.0142,  0.0594],\n",
      "        [-0.0113,  0.0664],\n",
      "        [-0.0115,  0.0737],\n",
      "        [-0.0138,  0.0421],\n",
      "        [-0.0121,  0.0359],\n",
      "        [-0.0149,  0.0464],\n",
      "        [-0.0181,  0.0231]], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "tensor([[-0.0311, -0.0230],\n",
      "        [-0.0297, -0.0265],\n",
      "        [-0.0284, -0.0267],\n",
      "        [-0.0302, -0.0321],\n",
      "        [-0.0289, -0.0331],\n",
      "        [-0.0274, -0.0307],\n",
      "        [-0.0290, -0.0328],\n",
      "        [-0.0275, -0.0313],\n",
      "        [-0.0292, -0.0292],\n",
      "        [-0.0276, -0.0267],\n",
      "        [-0.0258, -0.0224],\n",
      "        [-0.0275, -0.0187],\n",
      "        [-0.0257, -0.0123],\n",
      "        [-0.0273, -0.0166],\n",
      "        [-0.0252, -0.0078],\n",
      "        [-0.0269, -0.0093],\n",
      "        [-0.0246,  0.0221],\n",
      "        [-0.0263,  0.0207],\n",
      "        [-0.0280,  0.0165],\n",
      "        [-0.0299,  0.0156],\n",
      "        [-0.0318,  0.0146],\n",
      "        [-0.0338, -0.0085],\n",
      "        [ 0.3759,  0.1949],\n",
      "        [ 0.3490,  0.1609],\n",
      "        [ 0.3196,  0.1182],\n",
      "        [ 0.2901,  0.0789],\n",
      "        [ 0.2607,  0.0347],\n",
      "        [ 0.2344,  0.0074],\n",
      "        [ 0.2048, -0.0373],\n",
      "        [ 0.1758, -0.0832],\n",
      "        [ 0.1497, -0.0474],\n",
      "        [ 0.1202, -0.0879],\n",
      "        [ 0.0978, -0.1498],\n",
      "        [ 0.0696, -0.1781],\n",
      "        [ 0.0382, -0.2139],\n",
      "        [ 0.0091, -0.2305],\n",
      "        [-0.0229, -0.2639],\n",
      "        [-0.0521, -0.3137],\n",
      "        [-0.0744, -0.3370],\n",
      "        [-0.0737, -0.3313],\n",
      "        [-0.0756, -0.2764],\n",
      "        [-0.0740, -0.2737],\n",
      "        [-0.0679, -0.3202],\n",
      "        [-0.0654, -0.3223],\n",
      "        [-0.0658, -0.3343],\n",
      "        [-0.0627, -0.2343],\n",
      "        [-0.0589, -0.2447],\n",
      "        [-0.0531, -0.2548],\n",
      "        [-0.0506, -0.2607],\n",
      "        [-0.0514, -0.2723],\n",
      "        [-0.0494, -0.2393],\n",
      "        [-0.0472, -0.2460],\n",
      "        [-0.0483, -0.2086],\n",
      "        [-0.0461, -0.2170],\n",
      "        [-0.0470, -0.2302],\n",
      "        [-0.0450, -0.1164],\n",
      "        [-0.0429, -0.1245],\n",
      "        [-0.0410, -0.1267],\n",
      "        [-0.0395, -0.1322],\n",
      "        [-0.0409, -0.1416],\n",
      "        [-0.0391, -0.1298],\n",
      "        [-0.0375, -0.1359],\n",
      "        [-0.0392, -0.1037],\n",
      "        [-0.0374, -0.1110]], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "tensor([[-0.0421,  0.0902],\n",
      "        [-0.0436,  0.1053],\n",
      "        [-0.0354,  0.1633],\n",
      "        [-0.0380,  0.1440],\n",
      "        [-0.0376,  0.1390],\n",
      "        [-0.0399,  0.1476],\n",
      "        [-0.0476,  0.1663],\n",
      "        [-0.0485,  0.1007],\n",
      "        [-0.0532,  0.1772],\n",
      "        [-0.0608,  0.1637],\n",
      "        [-0.0746,  0.0553],\n",
      "        [-0.0835,  0.0200],\n",
      "        [-0.0930,  0.0504],\n",
      "        [-0.1017,  0.0162],\n",
      "        [-0.0973,  0.0361],\n",
      "        [-0.0897,  0.1251],\n",
      "        [-0.0521,  0.2141],\n",
      "        [-0.0577,  0.1220],\n",
      "        [-0.0705,  0.0708],\n",
      "        [-0.0854,  0.0187],\n",
      "        [-0.0964,  0.0110],\n",
      "        [-0.1086,  0.0333],\n",
      "        [-0.1141, -0.0840],\n",
      "        [-0.0877, -0.1145],\n",
      "        [-0.0836, -0.0747],\n",
      "        [-0.0867, -0.1087],\n",
      "        [-0.0972, -0.1471],\n",
      "        [-0.0946, -0.0854],\n",
      "        [-0.1049, -0.0947],\n",
      "        [-0.0829, -0.0949],\n",
      "        [-0.0731, -0.0947],\n",
      "        [-0.0758, -0.1315],\n",
      "        [-0.0829, -0.1796],\n",
      "        [-0.0819,  0.0692],\n",
      "        [-0.0836,  0.0600],\n",
      "        [-0.0622,  0.1354],\n",
      "        [-0.0519,  0.2020],\n",
      "        [-0.0520, -0.2496],\n",
      "        [-0.0491, -0.1979],\n",
      "        [-0.0448, -0.1516],\n",
      "        [-0.0451, -0.1407],\n",
      "        [-0.0466, -0.1257],\n",
      "        [-0.0410, -0.2644],\n",
      "        [-0.0380, -0.2433],\n",
      "        [-0.0345, -0.2110],\n",
      "        [-0.0371, -0.2201],\n",
      "        [-0.0323, -0.2293],\n",
      "        [-0.0330, -0.4098],\n",
      "        [-0.0300, -0.4001],\n",
      "        [-0.0259, -0.3769],\n",
      "        [-0.0265, -0.2531],\n",
      "        [-0.0182, -0.1615],\n",
      "        [-0.0156, -0.1822],\n",
      "        [-0.0175, -0.1801],\n",
      "        [-0.0142, -0.1001],\n",
      "        [-0.0155, -0.0919],\n",
      "        [-0.0192, -0.0210],\n",
      "        [-0.0167, -0.0160],\n",
      "        [-0.0104, -0.0824],\n",
      "        [-0.0062, -0.1062],\n",
      "        [-0.0049, -0.0902],\n",
      "        [-0.0110, -0.0105],\n",
      "        [-0.0101,  0.0200],\n",
      "        [-0.0143, -0.0034]], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "tensor([[-0.0306, -0.0106],\n",
      "        [-0.0325, -0.0171],\n",
      "        [-0.0313, -0.0048],\n",
      "        [-0.0301, -0.0061],\n",
      "        [-0.0319, -0.0148],\n",
      "        [-0.0306, -0.0122],\n",
      "        [-0.0293, -0.0141],\n",
      "        [-0.0311, -0.0069],\n",
      "        [-0.0299, -0.0066],\n",
      "        [-0.0317, -0.0326],\n",
      "        [-0.0303, -0.0317],\n",
      "        [-0.0291, -0.0310],\n",
      "        [-0.0309, -0.0238],\n",
      "        [-0.0296, -0.0184],\n",
      "        [-0.0286, -0.0145],\n",
      "        [-0.0305, -0.0135],\n",
      "        [-0.0290, -0.0146],\n",
      "        [-0.0278, -0.0232],\n",
      "        [-0.0296, -0.0266],\n",
      "        [-0.0283, -0.0297],\n",
      "        [-0.0269, -0.0298],\n",
      "        [-0.0286, -0.0301],\n",
      "        [-0.0271, -0.0301],\n",
      "        [-0.0289, -0.0323],\n",
      "        [-0.0273, -0.0378],\n",
      "        [-0.0255, -0.0306],\n",
      "        [-0.0272, -0.0314],\n",
      "        [-0.0254, -0.0224],\n",
      "        [-0.0270, -0.0269],\n",
      "        [-0.0250, -0.0096],\n",
      "        [-0.0267, -0.0128],\n",
      "        [-0.0245, -0.0010],\n",
      "        [-0.0261, -0.0082],\n",
      "        [-0.0278, -0.0123],\n",
      "        [-0.0296, -0.0149],\n",
      "        [-0.0314, -0.0144],\n",
      "        [-0.0334, -0.0131],\n",
      "        [-0.0354, -0.0187],\n",
      "        [-0.0376, -0.0193],\n",
      "        [-0.0398, -0.0233],\n",
      "        [-0.0422, -0.0243],\n",
      "        [ 0.5869,  0.1185],\n",
      "        [ 0.5565,  0.1114],\n",
      "        [ 0.5261,  0.1041],\n",
      "        [ 0.4955,  0.0968],\n",
      "        [ 0.4649,  0.0892],\n",
      "        [ 0.4374,  0.0820],\n",
      "        [ 0.4067,  0.0737],\n",
      "        [ 0.3759,  0.0651],\n",
      "        [ 0.3451,  0.0570],\n",
      "        [ 0.3173,  0.0502],\n",
      "        [ 0.2864,  0.0486],\n",
      "        [ 0.2553,  0.0399],\n",
      "        [ 0.2274,  0.0331],\n",
      "        [ 0.1962,  0.0237],\n",
      "        [ 0.1682,  0.0167],\n",
      "        [ 0.1368,  0.0152],\n",
      "        [ 0.1086,  0.0089],\n",
      "        [ 0.0771,  0.0022],\n",
      "        [ 0.0485,  0.0014],\n",
      "        [ 0.0167, -0.0042],\n",
      "        [-0.0120, -0.0146],\n",
      "        [-0.0339, -0.0178],\n",
      "        [-0.0328, -0.0157]], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "tensor(0.0200, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 23/28 [00:00<00:00, 102.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0398,  0.0129],\n",
      "        [-0.0396,  0.0025],\n",
      "        [-0.0396,  0.0267],\n",
      "        [-0.0421,  0.0398],\n",
      "        [-0.0423,  0.0483],\n",
      "        [-0.0420,  0.0397],\n",
      "        [-0.0419,  0.0614],\n",
      "        [-0.0429,  0.0964],\n",
      "        [-0.0488,  0.1392],\n",
      "        [-0.0515,  0.1444],\n",
      "        [-0.0556,  0.1299],\n",
      "        [-0.0629,  0.0827],\n",
      "        [-0.0412,  0.2479],\n",
      "        [-0.0437,  0.1799],\n",
      "        [-0.0457,  0.1929],\n",
      "        [-0.0524,  0.1642],\n",
      "        [-0.0613,  0.1244],\n",
      "        [-0.0743,  0.0917],\n",
      "        [-0.0875,  0.0650],\n",
      "        [-0.0974,  0.0633],\n",
      "        [-0.1110,  0.0354],\n",
      "        [-0.1188,  0.0129],\n",
      "        [-0.1278, -0.0327],\n",
      "        [-0.1232, -0.0241],\n",
      "        [-0.0624,  0.1624],\n",
      "        [-0.0768,  0.2890],\n",
      "        [-0.0897,  0.2056],\n",
      "        [-0.1080,  0.2331],\n",
      "        [-0.1201,  0.1999],\n",
      "        [-0.1299,  0.1660],\n",
      "        [-0.1363,  0.0679],\n",
      "        [-0.1363,  0.0944],\n",
      "        [-0.1187,  0.0585],\n",
      "        [-0.1044,  0.1132],\n",
      "        [-0.1196,  0.0811],\n",
      "        [-0.1343,  0.0589],\n",
      "        [-0.1404,  0.0396],\n",
      "        [-0.1044,  0.0746],\n",
      "        [-0.0973, -0.0809],\n",
      "        [-0.0998,  0.1423],\n",
      "        [-0.1031,  0.1393],\n",
      "        [-0.0962,  0.2057],\n",
      "        [-0.0669,  0.3208],\n",
      "        [-0.0628, -0.0634],\n",
      "        [-0.0627,  0.0390],\n",
      "        [-0.0609, -0.1555],\n",
      "        [-0.0576, -0.2421],\n",
      "        [-0.0553, -0.2235],\n",
      "        [-0.0512, -0.3533],\n",
      "        [-0.0491, -0.3426],\n",
      "        [-0.0502, -0.3420],\n",
      "        [-0.0474, -0.4089],\n",
      "        [-0.0475, -0.3801],\n",
      "        [-0.0497, -0.3451],\n",
      "        [-0.0509, -0.3295],\n",
      "        [-0.0429, -0.3114],\n",
      "        [-0.0431, -0.3291],\n",
      "        [-0.0450, -0.3187],\n",
      "        [-0.0313, -0.2893],\n",
      "        [-0.0300, -0.3016],\n",
      "        [-0.0276, -0.3142],\n",
      "        [-0.0248, -0.2409],\n",
      "        [-0.0257, -0.2176],\n",
      "        [-0.0265, -0.2194]], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "tensor(0.0231, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 106.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final val loss: 0.006180316496673706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model = Transformer(config_dict)\n",
    "model.load_state_dict(torch.load('models/transformer_model.pth', map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "device = 'cpu'\n",
    "\n",
    "# take world idx 0 as example\n",
    "dataset = KULBarnDataset(df[df['world_idx'] == 0], \"val\")\n",
    "print(len(dataset))\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "final_val_loss = test_model(model, loader, loss_fn)\n",
    "print(\"Final val loss:\", final_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "videocrafter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
